{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k3opHLYJRHCR"
   },
   "source": [
    "# Automatic Speech Recognition with Transformer\n",
    "\n",
    "**Author:** [Apoorv Nandan](https://twitter.com/NandanApoorv)<br>\n",
    "**Date created:** 2021/01/13<br>\n",
    "**Last modified:** 2021/01/13<br>\n",
    "**Description:** Training a sequence-to-sequence Transformer for automatic speech recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vNu5BNVtRHCW"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Automatic speech recognition (ASR) consists of transcribing audio speech segments into text.\n",
    "ASR can be treated as a sequence-to-sequence problem, where the\n",
    "audio can be represented as a sequence of feature vectors\n",
    "and the text as a sequence of characters, words, or subword tokens.\n",
    "\n",
    "For this demonstration, we will use the LJSpeech dataset from the\n",
    "[LibriVox](https://librivox.org/) project. It consists of short\n",
    "audio clips of a single speaker reading passages from 7 non-fiction books.\n",
    "Our model will be similar to the original Transformer (both encoder and decoder)\n",
    "as proposed in the paper, \"Attention is All You Need\".\n",
    "\n",
    "\n",
    "**References:**\n",
    "\n",
    "- [Attention is All You Need](https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)\n",
    "- [Very Deep Self-Attention Networks for End-to-End Speech Recognition](https://arxiv.org/abs/1904.13377)\n",
    "- [Speech Transformers](https://ieeexplore.ieee.org/document/8462506)\n",
    "- [LJSpeech Dataset](https://keithito.com/LJ-Speech-Dataset/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "DaN6AecBRHCX",
    "outputId": "63da7ee3-6437-49b4-b800-e20b163ac42b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n",
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import schedules\n",
    "import keras\n",
    "from keras import layers\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Lista todos os dispositivos físicos do tipo 'GPU'\n",
    "devices = tf.config.list_physical_devices('GPU')\n",
    "print(len(devices))  # Se o resultado for maior que 0, uma GPU está sendo usada\n",
    "\n",
    "# Verifica se o TensorFlow foi construído com suporte a CUDA\n",
    "print(tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OjOYcgmpRHCZ"
   },
   "source": [
    "## Define the Transformer Input Layer\n",
    "\n",
    "When processing past target tokens for the decoder, we compute the sum of\n",
    "position embeddings and token embeddings.\n",
    "\n",
    "When processing audio features, we apply convolutional layers to downsample\n",
    "them (via convolution strides) and process local relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Irr1T-O2RHCZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "class TokenEmbedding(layers.Layer):\n",
    "    def __init__(self, num_vocab=1000, maxlen=100, num_hid=64):\n",
    "        super().__init__()\n",
    "        self.emb = keras.layers.Embedding(num_vocab, num_hid)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=num_hid)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        x = self.emb(x)\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        return x + positions\n",
    "\n",
    "\n",
    "class SpeechFeatureEmbedding(layers.Layer):\n",
    "    def __init__(self, num_hid=64, maxlen=100):\n",
    "        super().__init__()\n",
    "        self.conv1 = keras.layers.Conv1D(\n",
    "            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv2 = keras.layers.Conv1D(\n",
    "            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv3 = keras.layers.Conv1D(\n",
    "            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        return self.conv3(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ab14XhPRHCa"
   },
   "source": [
    "## Transformer Encoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SpEtRUFDRHCb"
   },
   "outputs": [],
   "source": [
    "\n",
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, feed_forward_dim, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(feed_forward_dim, activation=\"relu\"),\n",
    "                layers.Dense(embed_dim),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfsTgZ6vRHCb"
   },
   "source": [
    "## Transformer Decoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "LRksSL9oRHCc"
   },
   "outputs": [],
   "source": [
    "\n",
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, feed_forward_dim, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.self_att = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.enc_att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.self_dropout = layers.Dropout(0.5)\n",
    "        self.enc_dropout = layers.Dropout(0.1)\n",
    "        self.ffn_dropout = layers.Dropout(0.1)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(feed_forward_dim, activation=\"relu\"),\n",
    "                layers.Dense(embed_dim),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def causal_attention_mask(self, batch_size, n_dest, n_src, dtype):\n",
    "        \"\"\"Masks the upper half of the dot product matrix in self attention.\n",
    "\n",
    "        This prevents flow of information from future tokens to current token.\n",
    "        1's in the lower triangle, counting from the lower right corner.\n",
    "        \"\"\"\n",
    "        i = tf.range(n_dest)[:, None]\n",
    "        j = tf.range(n_src)\n",
    "        m = i >= j - n_src + n_dest\n",
    "        mask = tf.cast(m, dtype)\n",
    "        mask = tf.reshape(mask, [1, n_dest, n_src])\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)], 0\n",
    "        )\n",
    "        return tf.tile(mask, mult)\n",
    "\n",
    "    def call(self, enc_out, target):\n",
    "        input_shape = tf.shape(target)\n",
    "        batch_size = input_shape[0]\n",
    "        seq_len = input_shape[1]\n",
    "        causal_mask = self.causal_attention_mask(batch_size, seq_len, seq_len, tf.bool)\n",
    "        target_att = self.self_att(target, target, attention_mask=causal_mask)\n",
    "        target_norm = self.layernorm1(target + self.self_dropout(target_att))\n",
    "        enc_out = self.enc_att(target_norm, enc_out)\n",
    "        enc_out_norm = self.layernorm2(self.enc_dropout(enc_out) + target_norm)\n",
    "        ffn_out = self.ffn(enc_out_norm)\n",
    "        ffn_out_norm = self.layernorm3(enc_out_norm + self.ffn_dropout(ffn_out))\n",
    "        return ffn_out_norm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d55jG_L0RHCc"
   },
   "source": [
    "## Complete the Transformer model\n",
    "\n",
    "Our model takes audio spectrograms as inputs and predicts a sequence of characters.\n",
    "During training, we give the decoder the target character sequence shifted to the left\n",
    "as input. During inference, the decoder uses its own past predictions to predict the\n",
    "next token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "OgptmFnFRHCd"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_hid=64,\n",
    "        num_head=2,\n",
    "        num_feed_forward=128,\n",
    "        source_maxlen=100,\n",
    "        target_maxlen=100,\n",
    "        num_layers_enc=4,\n",
    "        num_layers_dec=1,\n",
    "        num_classes=10,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.loss_metric = tf.keras.metrics.Mean(name=\"loss\")\n",
    "        self.num_layers_enc = num_layers_enc\n",
    "        self.num_layers_dec = num_layers_dec\n",
    "        self.target_maxlen = target_maxlen\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.enc_input = SpeechFeatureEmbedding(num_hid=num_hid, maxlen=source_maxlen)\n",
    "        self.dec_input = TokenEmbedding(\n",
    "            num_vocab=num_classes, maxlen=target_maxlen, num_hid=num_hid\n",
    "        )\n",
    "\n",
    "        self.encoder = tf.keras.Sequential(\n",
    "            [self.enc_input]\n",
    "            + [\n",
    "                TransformerEncoder(num_hid, num_head, num_feed_forward)\n",
    "                for _ in range(num_layers_enc)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        for i in range(num_layers_dec):\n",
    "            setattr(\n",
    "                self,\n",
    "                f\"dec_layer_{i}\",\n",
    "                TransformerDecoder(num_hid, num_head, num_feed_forward),\n",
    "            )\n",
    "\n",
    "        self.classifier = layers.Dense(num_classes)\n",
    "\n",
    "    def decode(self, enc_out, target):\n",
    "        y = self.dec_input(target)\n",
    "        for i in range(self.num_layers_dec):\n",
    "            y = getattr(self, f\"dec_layer_{i}\")(enc_out, y)\n",
    "        return y\n",
    "\n",
    "    def call(self, inputs):\n",
    "        source = inputs[0]\n",
    "        target = inputs[1]\n",
    "        x = self.encoder(source)\n",
    "        y = self.decode(x, target)\n",
    "        return self.classifier(y)\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.loss_metric]\n",
    "    \n",
    "    def train_step(self, batch):\n",
    "        \"\"\"Processes one batch inside model.fit().\"\"\"\n",
    "        source = batch[\"source\"]\n",
    "        target = batch[\"target\"]\n",
    "        dec_input = target[:, :-1]\n",
    "        dec_target = target[:, 1:]\n",
    "        with tf.GradientTape() as tape:\n",
    "            preds = self([source, dec_input])\n",
    "            one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n",
    "            mask = tf.math.logical_not(tf.math.equal(dec_target, 0))\n",
    "            loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "            loss = loss_object(one_hot, preds, sample_weight=mask)\n",
    "\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        self.loss_metric.update_state(loss)\n",
    "        return {\"loss\": self.loss_metric.result()}\n",
    "\n",
    "    def test_step(self, batch):\n",
    "        source = batch[\"source\"]\n",
    "        target = batch[\"target\"]\n",
    "        dec_input = target[:, :-1]\n",
    "        dec_target = target[:, 1:]\n",
    "        preds = self([source, dec_input])\n",
    "        one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n",
    "        mask = tf.math.logical_not(tf.math.equal(dec_target, 0))\n",
    "        loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "        loss = loss_object(one_hot, preds, sample_weight=mask)\n",
    "\n",
    "        self.loss_metric.update_state(loss)\n",
    "        return {\"loss\": self.loss_metric.result()}\n",
    "\n",
    "    def generate(self, source, target_start_token_idx):\n",
    "        \"\"\"Performs inference over one batch of inputs using greedy decoding.\"\"\"\n",
    "        bs = tf.shape(source)[0]\n",
    "        enc = self.encoder(source)\n",
    "        dec_input = tf.ones((bs, 1), dtype=tf.int32) * target_start_token_idx\n",
    "        dec_logits = []\n",
    "        for i in range(self.target_maxlen - 1):\n",
    "            dec_out = self.decode(enc, dec_input)\n",
    "            logits = self.classifier(dec_out)\n",
    "            logits = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
    "            last_logit = tf.expand_dims(logits[:, -1], axis=-1)\n",
    "            dec_logits.append(last_logit)\n",
    "            dec_input = tf.concat([dec_input, last_logit], axis=-1)\n",
    "        return dec_input\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "liuKciSRRHCd"
   },
   "source": [
    "## Download the dataset\n",
    "\n",
    "Note: This requires ~3.6 GB of disk space and\n",
    "takes ~5 minutes for the extraction of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "au3uVjM1RHCd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "keras.utils.get_file(\n",
    "    os.path.join(os.getcwd(), \"data.tar.gz\"),\n",
    "    \"https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\",\n",
    "    extract=True,\n",
    "    archive_format=\"tar\",\n",
    "    cache_dir=\".\",\n",
    ")\n",
    "'''\n",
    "\n",
    "saveto = \".\\\\datasets\\\\LJSpeech-1.1\"\n",
    "wavs = glob(\"{}\\\\**\\\\*.wav\".format(saveto), recursive=True)\n",
    "#print(wavs)\n",
    "id_to_text = {}\n",
    "with open(os.path.join(saveto, \"metadata.csv\"), encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        id = line.strip().split(\"|\")[0]\n",
    "        text = line.strip().split(\"|\")[2]\n",
    "        id_to_text[id] = text\n",
    "\n",
    "\n",
    "def get_data(wavs, id_to_text, maxlen=50):\n",
    "    \"\"\"returns mapping of audio paths and transcription texts\"\"\"\n",
    "    data = []\n",
    "    for w in wavs:\n",
    "        id = w.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "        if len(id_to_text[id]) < maxlen:\n",
    "            data.append({\"audio\": w, \"text\": id_to_text[id]})\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4eTa9km4RHCe"
   },
   "source": [
    "## Preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "2mxWQLOARHCe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size 34\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class VectorizeChar:\n",
    "    def __init__(self, max_len=50):\n",
    "        self.vocab = (\n",
    "            [\"-\", \"#\", \"<\", \">\"]\n",
    "            + [chr(i + 96) for i in range(1, 27)]\n",
    "            + [\" \", \".\", \",\", \"?\"]\n",
    "        )\n",
    "        self.max_len = max_len\n",
    "        self.char_to_idx = {}\n",
    "        for i, ch in enumerate(self.vocab):\n",
    "            self.char_to_idx[ch] = i\n",
    "\n",
    "    def __call__(self, text):\n",
    "        text = text.lower()\n",
    "        text = text[: self.max_len - 2]\n",
    "        text = \"<\" + text + \">\"\n",
    "        pad_len = self.max_len - len(text)\n",
    "        return [self.char_to_idx.get(ch, 1) for ch in text] + [0] * pad_len\n",
    "\n",
    "    def get_vocabulary(self):\n",
    "        return self.vocab\n",
    "\n",
    "\n",
    "max_target_len = 200  # all transcripts in out data are < 200 characters\n",
    "data = get_data(wavs, id_to_text, max_target_len)\n",
    "vectorizer = VectorizeChar(max_target_len)\n",
    "print(\"vocab size\", len(vectorizer.get_vocabulary()))\n",
    "\n",
    "\n",
    "def create_text_ds(data):\n",
    "    texts = [_[\"text\"] for _ in data]\n",
    "    text_ds = [vectorizer(t) for t in texts]\n",
    "    text_ds = tf.data.Dataset.from_tensor_slices(text_ds)\n",
    "    return text_ds\n",
    "\n",
    "\n",
    "def path_to_audio(path):\n",
    "    # spectrogram using stft\n",
    "    audio = tf.io.read_file(path)\n",
    "    audio, _ = tf.audio.decode_wav(audio, 1)\n",
    "    audio = tf.squeeze(audio, axis=-1)\n",
    "    stfts = tf.signal.stft(audio, frame_length=200, frame_step=80, fft_length=256)\n",
    "    x = tf.math.pow(tf.abs(stfts), 0.5)\n",
    "    # normalisation\n",
    "    means = tf.math.reduce_mean(x, 1, keepdims=True)\n",
    "    stddevs = tf.math.reduce_std(x, 1, keepdims=True)\n",
    "    x = (x - means) / stddevs\n",
    "    audio_len = tf.shape(x)[0]\n",
    "    # padding to 10 seconds\n",
    "    pad_len = 2754\n",
    "    paddings = tf.constant([[0, pad_len], [0, 0]])\n",
    "    x = tf.pad(x, paddings, \"CONSTANT\")[:pad_len, :]\n",
    "    return x\n",
    "\n",
    "\n",
    "def create_audio_ds(data):\n",
    "    flist = [_[\"audio\"] for _ in data]\n",
    "    audio_ds = tf.data.Dataset.from_tensor_slices(flist)\n",
    "    audio_ds = audio_ds.map(path_to_audio, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return audio_ds\n",
    "\n",
    "\n",
    "def create_tf_dataset(data, bs=4):\n",
    "    audio_ds = create_audio_ds(data)\n",
    "    text_ds = create_text_ds(data)\n",
    "    ds = tf.data.Dataset.zip((audio_ds, text_ds))\n",
    "    ds = ds.map(lambda x, y: {\"source\": x, \"target\": y})\n",
    "    ds = ds.batch(bs)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "\n",
    "split = int(len(data) * 0.99)\n",
    "train_data = data[:split]\n",
    "test_data = data[split:]\n",
    "ds = create_tf_dataset(train_data, bs=64)\n",
    "val_ds = create_tf_dataset(test_data, bs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "szBaODmsRHCg"
   },
   "source": [
    "## Callbacks to display predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "1L-YvvMxRHCg"
   },
   "outputs": [],
   "source": [
    "\n",
    "class DisplayOutputs(keras.callbacks.Callback):\n",
    "    def __init__(\n",
    "        self, batch, idx_to_token, target_start_token_idx=27, target_end_token_idx=28\n",
    "    ):\n",
    "        \"\"\"Displays a batch of outputs after every epoch\n",
    "\n",
    "        Args:\n",
    "            batch: A test batch containing the keys \"source\" and \"target\"\n",
    "            idx_to_token: A List containing the vocabulary tokens corresponding to their indices\n",
    "            target_start_token_idx: A start token index in the target vocabulary\n",
    "            target_end_token_idx: An end token index in the target vocabulary\n",
    "        \"\"\"\n",
    "        self.batch = batch\n",
    "        self.target_start_token_idx = target_start_token_idx\n",
    "        self.target_end_token_idx = target_end_token_idx\n",
    "        self.idx_to_char = idx_to_token\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % 5 != 0:\n",
    "            return\n",
    "        source = self.batch[\"source\"]\n",
    "        target = self.batch[\"target\"].numpy()\n",
    "        bs = tf.shape(source)[0]\n",
    "        preds = self.model.generate(source, self.target_start_token_idx)\n",
    "        preds = preds.numpy()\n",
    "        for i in range(bs):\n",
    "            target_text = \"\".join([self.idx_to_char[_] for _ in target[i, :]])\n",
    "            prediction = \"\"\n",
    "            for idx in preds[i, :]:\n",
    "                prediction += self.idx_to_char[idx]\n",
    "                if idx == self.target_end_token_idx:\n",
    "                    break\n",
    "            print(f\"target:     {target_text.replace('-','')}\")\n",
    "            print(f\"prediction: {prediction}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6JfOL_oARHCg"
   },
   "source": [
    "## Learning rate schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "D-dRLFkNRHCh"
   },
   "outputs": [],
   "source": [
    "\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        init_lr=0.00001,\n",
    "        lr_after_warmup=0.001,\n",
    "        final_lr=0.00001,\n",
    "        warmup_epochs=15,\n",
    "        decay_epochs=85,\n",
    "        steps_per_epoch=203,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.init_lr = init_lr\n",
    "        self.lr_after_warmup = lr_after_warmup\n",
    "        self.final_lr = final_lr\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.decay_epochs = decay_epochs\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "\n",
    "    def calculate_lr(self, epoch):\n",
    "        \"\"\"linear warm up - linear decay\"\"\"\n",
    "        warmup_lr = (\n",
    "            self.init_lr\n",
    "            + ((self.lr_after_warmup - self.init_lr) / (self.warmup_epochs - 1)) * epoch\n",
    "        )\n",
    "        decay_lr = tf.math.maximum(\n",
    "            self.final_lr,\n",
    "            self.lr_after_warmup\n",
    "            - (epoch - self.warmup_epochs)\n",
    "            * (self.lr_after_warmup - self.final_lr)\n",
    "            / self.decay_epochs,\n",
    "        )\n",
    "        return tf.math.minimum(warmup_lr, decay_lr)\n",
    "\n",
    "    def __call__(self, step):\n",
    "        epoch = step // self.steps_per_epoch\n",
    "        epoch = tf.cast(epoch, \"float32\")\n",
    "        return self.calculate_lr(epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ne33ZwMORHCh"
   },
   "source": [
    "## Create & train the end-to-end model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salva e carrega o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_callbacks(display_cb, filepath):\n",
    "    # Função para salvar o melhor modelo baseado na perda de validação\n",
    "    model_checkpoint_callback = ModelCheckpoint(\n",
    "        filepath=filepath,\n",
    "        save_weights_only=True,\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_best_only=True)\n",
    "\n",
    "    # Adicione model_checkpoint_callback à lista de callbacks.\n",
    "    callbacks_list = [display_cb, model_checkpoint_callback]\n",
    "    return callbacks_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(ckpt, manager):\n",
    "    # Função para retomar o treinamento de onde parou\n",
    "    ckpt.restore(manager.latest_checkpoint)\n",
    "    if manager.latest_checkpoint:\n",
    "        print(\"Restaurado de {}\".format(manager.latest_checkpoint))\n",
    "    else:\n",
    "        print(\"Inicializando do zero.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "bby6svtcRHCh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "203/203 [==============================] - ETA: 0s - loss: 1.7369target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <aaie te t  t h taa  nhe n ote t tenee t o te t t t t t the  te ta o tan ion t  hat  ote t t te n t tes te ta nnis t  ot te t t te t ae t oten ot t te ritsoa aot te e t tare ote ot t trio t is  ot o r\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <aaie t te  t h taa  nhe n ote t tenee t o te t t t t t the  te ta o tan ion t  hat  ote t t t taa niis te ta n aa t  ot te t t te t ae t oten ot t te ritsoa aot te e t tare ote ot t trio t is  ot o r\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <aaie te t  t h taa  nhe n ote t tenee t o te t t t t t the  te ta o tan ion t  hat  ote t t te n t tes te ta nnis t  ot te t t te t ae t oten ot t te ritsoa aot te e t tare ote ot t trio t is  ot o r\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <aaie t te  t h taa  nhe n ote t tenee t o te t t t t t the  te ta o tan ion t  hat  ote t t t taa niis te ta n aa t  ot te t t te t ae t oten ot t te ritsoa aot te e t tare ote ot t trio t is  ot o r\n",
      "\n",
      "203/203 [==============================] - 85s 388ms/step - loss: 1.7369 - val_loss: 1.6157\n",
      "Epoch 2/200\n",
      "203/203 [==============================] - 78s 385ms/step - loss: 1.3080 - val_loss: 1.3127\n",
      "Epoch 3/200\n",
      "203/203 [==============================] - 82s 405ms/step - loss: 1.2045 - val_loss: 1.2639\n",
      "Epoch 4/200\n",
      "203/203 [==============================] - 80s 392ms/step - loss: 1.1838 - val_loss: 1.2504\n",
      "Epoch 5/200\n",
      "203/203 [==============================] - 81s 399ms/step - loss: 1.1747 - val_loss: 1.2374\n",
      "Epoch 6/200\n",
      "203/203 [==============================] - ETA: 0s - loss: 1.1664target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the pre the ofof the the the the the the the the the the the the the ore the the the the the sisisiofore the the the t>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <the pre the ofof the the the the the the of the the the the sise ase the ofofof the the the of the of the the se the the se the the the the the the pre sinofof pre presidentheennedy.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <the se the ofof the the the the se the the the ofof the the the sise ore the there ofore the sisisice thes.>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <the pre the ofore the the the the the se asin the ofof the ore the the the the the ore the the the of the the se the the se the the the the the the pre sinofore of president kennedy.>\n",
      "\n",
      "203/203 [==============================] - 84s 413ms/step - loss: 1.1664 - val_loss: 1.2273\n",
      "Epoch 7/200\n",
      "203/203 [==============================] - 80s 391ms/step - loss: 1.1555 - val_loss: 1.2092\n",
      "Epoch 8/200\n",
      "203/203 [==============================] - 81s 396ms/step - loss: 1.1292 - val_loss: 1.1585\n",
      "Epoch 9/200\n",
      "203/203 [==============================] - 82s 404ms/step - loss: 1.0534 - val_loss: 1.0437\n",
      "Epoch 10/200\n",
      "203/203 [==============================] - 81s 399ms/step - loss: 0.9741 - val_loss: 0.9618\n",
      "Epoch 11/200\n",
      "203/203 [==============================] - ETA: 0s - loss: 0.9095target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the president secret secret sevence secret secret secret subiliation of the secret.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <commities of the secomment the secommities of the secomment the secomment the subilical assident astated the t t the se tenden ten the ten tendenden tendenend.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <in secresting the secresties of the sestance of the secresibilit.>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <in the secomment of the secommities of the secret of the secret secomment of the secret secie of the secret te at the t sesentesesese sese tentes.>\n",
      "\n",
      "203/203 [==============================] - 85s 419ms/step - loss: 0.9095 - val_loss: 0.8822\n",
      "Epoch 12/200\n",
      "203/203 [==============================] - 80s 391ms/step - loss: 0.8394 - val_loss: 0.7841\n",
      "Epoch 13/200\n",
      "203/203 [==============================] - 81s 397ms/step - loss: 0.7256 - val_loss: 0.6608\n",
      "Epoch 14/200\n",
      "203/203 [==============================] - 98s 481ms/step - loss: 0.6185 - val_loss: 0.5757\n",
      "Epoch 15/200\n",
      "203/203 [==============================] - 92s 451ms/step - loss: 0.5496 - val_loss: 0.5317\n",
      "Epoch 16/200\n",
      "203/203 [==============================] - ETA: 0s - loss: 0.4921target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the information suplied by mate other agent fromation suplied.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <presit the clase of them or subject the are affices of the are suffices of the are affict presity of asstity of presity ty t pren.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its presistime many sulling sistime to many sulling sistime of is on is on is on is on is on is on is on is on t>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it make make sussing developments in the buisent aliments in the buisments dend in the buisments in the busismen and in t athen an an orenden alllendes.>\n",
      "\n",
      "203/203 [==============================] - 91s 444ms/step - loss: 0.4921 - val_loss: 0.4960\n",
      "Epoch 17/200\n",
      "203/203 [==============================] - 89s 435ms/step - loss: 0.4467 - val_loss: 0.4630\n",
      "Epoch 18/200\n",
      "203/203 [==============================] - 82s 400ms/step - loss: 0.4184 - val_loss: 0.4472\n",
      "Epoch 19/200\n",
      "203/203 [==============================] - 78s 384ms/step - loss: 0.3876 - val_loss: 0.4274\n",
      "Epoch 20/200\n",
      "203/203 [==============================] - 79s 388ms/step - loss: 0.3613 - val_loss: 0.4195\n",
      "Epoch 21/200\n",
      "203/203 [==============================] - ETA: 0s - loss: 0.3420target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <these disted suciplied by villibi vice informations will be nformations wise wised.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <prs office preside refice prects on more subject breaffic presidentive refice presidentive reaffice presidentivele the clofiven.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present manulangely phillings is on is present.>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it make the businessing which a made process no of the recous dince din of the recouse of the reconsing which alt developmencesesentencencences.>\n",
      "\n",
      "203/203 [==============================] - 84s 410ms/step - loss: 0.3420 - val_loss: 0.4218\n",
      "Epoch 22/200\n",
      "203/203 [==============================] - 78s 383ms/step - loss: 0.3293 - val_loss: 0.4139\n",
      "Epoch 23/200\n",
      "203/203 [==============================] - 79s 388ms/step - loss: 0.3203 - val_loss: 0.4025\n",
      "Epoch 24/200\n",
      "203/203 [==============================] - 78s 384ms/step - loss: 0.3143 - val_loss: 0.3833\n",
      "Epoch 25/200\n",
      "203/203 [==============================] - 82s 401ms/step - loss: 0.2903 - val_loss: 0.3835\n",
      "Epoch 26/200\n",
      "203/203 [==============================] - ETA: 0s - loss: 0.2705target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the information creasied other agenciplie was was will be was was was was was was was was was was was was wais was was was s t.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <prs officied that subject breated bassist occlass ought the classed to classed to classes of graphic presity obasisity obaty t d t bre bre.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present manual filing stom enula filing stom enula filing sobstimulang stome enula filingst>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it make made made of the rescknow used developments and in other govelopments and in other governments in othe business weredededencencets.>\n",
      "\n",
      "203/203 [==============================] - 83s 409ms/step - loss: 0.2705 - val_loss: 0.3827\n",
      "Epoch 27/200\n",
      "203/203 [==============================] - 80s 394ms/step - loss: 0.2603 - val_loss: 0.3948\n",
      "Epoch 28/200\n",
      "203/203 [==============================] - 81s 399ms/step - loss: 0.2685 - val_loss: 0.3970\n",
      "Epoch 29/200\n",
      "203/203 [==============================] - 80s 392ms/step - loss: 0.2535 - val_loss: 0.3583\n",
      "Epoch 30/200\n",
      "203/203 [==============================] - 80s 393ms/step - loss: 0.2278 - val_loss: 0.3519\n",
      "Epoch 31/200\n",
      "203/203 [==============================] - ETA: 0s - loss: 0.3011target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the information supling weith by be magent.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <prs than the prs than the preside than the preside raficated be subject presity to class ome ware subject presity to classed be subject dem.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present manual filing son filling son filievely eaut.>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it makes white developments in other govelopments in other white developments in other governments in other governments in other government overnces.>\n",
      "\n",
      "203/203 [==============================] - 86s 422ms/step - loss: 0.3011 - val_loss: 0.3315\n",
      "Epoch 32/200\n",
      "203/203 [==============================] - 81s 396ms/step - loss: 0.2463 - val_loss: 0.3163\n",
      "Epoch 33/200\n",
      "203/203 [==============================] - 81s 396ms/step - loss: 0.2058 - val_loss: 0.3360\n",
      "Epoch 34/200\n",
      "203/203 [==============================] - 81s 396ms/step - loss: 0.2010 - val_loss: 0.3290\n",
      "Epoch 35/200\n",
      "203/203 [==============================] - 81s 399ms/step - loss: 0.2249 - val_loss: 0.3034\n",
      "Epoch 36/200\n",
      "203/203 [==============================] - ETA: 0s - loss: 0.2021target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <thest inciplied by by by believe was bloobil be was bline was bulbil be lieve was bulbing waised.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <prs the classity to classity to classity to classity to classity to classity to classity to classity to clast to classity to classiden.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present manual filing sole file file file file filling some andual fillings manual fillingst>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it made made appross of the rescond developments developments in other governments developments in other governments developments.>\n",
      "\n",
      "203/203 [==============================] - 83s 405ms/step - loss: 0.2021 - val_loss: 0.2998\n",
      "Epoch 37/200\n",
      "203/203 [==============================] - 81s 396ms/step - loss: 0.1813 - val_loss: 0.3028\n",
      "Epoch 38/200\n",
      "203/203 [==============================] - 79s 387ms/step - loss: 0.1670 - val_loss: 0.3066\n",
      "Epoch 39/200\n",
      "203/203 [==============================] - 80s 392ms/step - loss: 0.1679 - val_loss: 0.3086\n",
      "Epoch 40/200\n",
      "203/203 [==============================] - 78s 385ms/step - loss: 0.1668 - val_loss: 0.3074\n",
      "Epoch 41/200\n",
      "203/203 [==============================] - ETA: 0s - loss: 0.1519target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the increased information supplie by by by bell be lin creased infromation suciplied.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <prs must the classity to cated basis in jewgerest the are geographc beases in jewgerest than the presengy are geographes in juct beasis a geouth and t an.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present manual file the the manual filing soling soling solingst a manual file the.>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it makes in of the recent in of the recent developments in of the recent developments in of the recent developments in of the recent in of the recents.>\n",
      "\n",
      "203/203 [==============================] - 83s 405ms/step - loss: 0.1519 - val_loss: 0.3124\n",
      "Epoch 42/200\n",
      "203/203 [==============================] - 79s 389ms/step - loss: 0.1516 - val_loss: 0.3250\n",
      "Epoch 43/200\n",
      "203/203 [==============================] - 80s 394ms/step - loss: 0.1574 - val_loss: 0.3098\n",
      "Epoch 44/200\n",
      "203/203 [==============================] - 78s 382ms/step - loss: 0.1358 - val_loss: 0.3265\n",
      "Epoch 45/200\n",
      "203/203 [==============================] - 78s 384ms/step - loss: 0.1344 - val_loss: 0.3223\n",
      "Epoch 46/200\n",
      "203/203 [==============================] - ETA: 0s - loss: 0.1469target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the increased information suckiplie was will be wasted.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <prs of is must develop thic presity agraphic breat develop thic present to classity to classes of ject presity to classes in june.m.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present manual file the sobsobson is osystem esobve fillingst manual file the.>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it matematic developments in the business in of the recent developments developments in of the recent developments in of the resonsing, which ausdents.>\n",
      "\n",
      "203/203 [==============================] - 81s 399ms/step - loss: 0.1469 - val_loss: 0.3197\n",
      "Epoch 47/200\n",
      "203/203 [==============================] - 79s 387ms/step - loss: 0.1567 - val_loss: 0.3478\n",
      "Epoch 48/200\n",
      "113/203 [===============>..............] - ETA: 36s - loss: 0.2341"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate)\n\u001b[0;32m     32\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39mloss_fn)\n\u001b[1;32m---> 34\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mdisplay_cb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\asr_keras\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\asr_keras\\lib\\site-packages\\keras\\engine\\training.py:1221\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1219\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs  \u001b[38;5;66;03m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[1;32m-> 1221\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[0;32m   1223\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\asr_keras\\lib\\site-packages\\keras\\callbacks.py:436\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    430\u001b[0m \n\u001b[0;32m    431\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 436\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\asr_keras\\lib\\site-packages\\keras\\callbacks.py:295\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    293\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 295\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    297\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    298\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Expected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\asr_keras\\lib\\site-packages\\keras\\callbacks.py:316\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    313\u001b[0m   batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[0;32m    314\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 316\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    319\u001b[0m   end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\asr_keras\\lib\\site-packages\\keras\\callbacks.py:354\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m    353\u001b[0m   hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 354\u001b[0m   \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[0;32m    357\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\asr_keras\\lib\\site-packages\\keras\\callbacks.py:1032\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 1032\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\asr_keras\\lib\\site-packages\\keras\\callbacks.py:1104\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[0;32m   1102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1103\u001b[0m   \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m-> 1104\u001b[0m   logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1105\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\asr_keras\\lib\\site-packages\\keras\\utils\\tf_utils.py:554\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(x) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m x\n\u001b[0;32m    552\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m t  \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m--> 554\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\asr_keras\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:869\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    865\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    866\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 869\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    870\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\asr_keras\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:869\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    865\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    866\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 869\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    870\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\asr_keras\\lib\\site-packages\\keras\\utils\\tf_utils.py:550\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    549\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m--> 550\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(x) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m x\n\u001b[0;32m    552\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\asr_keras\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1149\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \n\u001b[0;32m   1128\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1148\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1149\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\asr_keras\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1115\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1114\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1116\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch = next(iter(val_ds))\n",
    "\n",
    "# The vocabulary to convert predicted indices into characters\n",
    "idx_to_char = vectorizer.get_vocabulary()\n",
    "display_cb = DisplayOutputs(\n",
    "    batch, idx_to_char, target_start_token_idx=2, target_end_token_idx=3\n",
    ")  # set the arguments as per vocabulary index for '<' and '>'\n",
    "\n",
    "model = Transformer(\n",
    "    num_hid=200,\n",
    "    num_head=2,\n",
    "    num_feed_forward=400,\n",
    "    target_maxlen=max_target_len,\n",
    "    num_layers_enc=4,\n",
    "    num_layers_dec=1,\n",
    "    num_classes=34,\n",
    ")\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "    label_smoothing=0.1,\n",
    ")\n",
    "\n",
    "learning_rate = CustomSchedule(\n",
    "    init_lr=0.00001,\n",
    "    lr_after_warmup=0.001,\n",
    "    final_lr=0.00001,\n",
    "    warmup_epochs=15,\n",
    "    decay_epochs=85,\n",
    "    steps_per_epoch=len(ds),\n",
    ")\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "model.compile(optimizer=optimizer, loss=loss_fn)\n",
    "\n",
    "# Crie os callbacks\n",
    "callbacks_list = create_callbacks(display_cb, './tmp/chechpoint_arch1/')\n",
    "callbacks_list.append(tensorboard_callback)\n",
    "# Crie o gerenciador de checkpoints\n",
    "ckpt = tf.train.Checkpoint(optimizer=optimizer, model=model)\n",
    "manager = tf.train.CheckpointManager(ckpt, './tf_ckpts_arch1/', max_to_keep=3)\n",
    "\n",
    "# Carregue o último checkpoint\n",
    "load_checkpoint(ckpt, manager)\n",
    "\n",
    "history = model.fit(ds, validation_data=val_ds, callbacks=callbacks_list, epochs=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AWXGWnClRHCi"
   },
   "source": [
    "In practice, you should train for around 100 epochs or more.\n",
    "\n",
    "Some of the predicted text at or around epoch 35 may look as follows:\n",
    "```\n",
    "target:     <as they sat in the car, frazier asked oswald where his lunch was>\n",
    "prediction: <as they sat in the car frazier his lunch ware mis lunch was>\n",
    "\n",
    "target:     <under the entry for may one, nineteen sixty,>\n",
    "prediction: <under the introus for may monee, nin the sixty,>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "transformer_asr",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
