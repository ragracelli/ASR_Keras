{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k3opHLYJRHCR"
   },
   "source": [
    "# Automatic Speech Recognition with Transformer\n",
    "\n",
    "**Author:** [Apoorv Nandan](https://twitter.com/NandanApoorv)<br>\n",
    "**Date created:** 2021/01/13<br>\n",
    "**Last modified:** 2021/01/13<br>\n",
    "**Description:** Training a sequence-to-sequence Transformer for automatic speech recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vNu5BNVtRHCW"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Automatic speech recognition (ASR) consists of transcribing audio speech segments into text.\n",
    "ASR can be treated as a sequence-to-sequence problem, where the\n",
    "audio can be represented as a sequence of feature vectors\n",
    "and the text as a sequence of characters, words, or subword tokens.\n",
    "\n",
    "For this demonstration, we will use the LJSpeech dataset from the\n",
    "[LibriVox](https://librivox.org/) project. It consists of short\n",
    "audio clips of a single speaker reading passages from 7 non-fiction books.\n",
    "Our model will be similar to the original Transformer (both encoder and decoder)\n",
    "as proposed in the paper, \"Attention is All You Need\".\n",
    "\n",
    "\n",
    "**References:**\n",
    "\n",
    "- [Attention is All You Need](https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)\n",
    "- [Very Deep Self-Attention Networks for End-to-End Speech Recognition](https://arxiv.org/abs/1904.13377)\n",
    "- [Speech Transformers](https://ieeexplore.ieee.org/document/8462506)\n",
    "- [LJSpeech Dataset](https://keithito.com/LJ-Speech-Dataset/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "DaN6AecBRHCX",
    "outputId": "63da7ee3-6437-49b4-b800-e20b163ac42b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n",
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import schedules\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'  # ou qualquer número de 0 a 3\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "import datetime\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Lista todos os dispositivos físicos do tipo 'GPU'\n",
    "devices = tf.config.list_physical_devices('GPU')\n",
    "print(len(devices))  # Se o resultado for maior que 0, uma GPU está sendo usada\n",
    "\n",
    "# Verifica se o TensorFlow foi construído com suporte a CUDA\n",
    "print(tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OjOYcgmpRHCZ"
   },
   "source": [
    "## Define the Transformer Input Layer\n",
    "\n",
    "When processing past target tokens for the decoder, we compute the sum of\n",
    "position embeddings and token embeddings.\n",
    "\n",
    "When processing audio features, we apply convolutional layers to downsample\n",
    "them (via convolution strides) and process local relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Irr1T-O2RHCZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "class TokenEmbedding(layers.Layer):\n",
    "    def __init__(self, num_vocab=1000, maxlen=100, num_hid=64):\n",
    "        super().__init__()\n",
    "        self.emb = keras.layers.Embedding(num_vocab, num_hid)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=num_hid)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        x = self.emb(x)\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        return x + positions\n",
    "\n",
    "\n",
    "class SpeechFeatureEmbedding(layers.Layer):\n",
    "    def __init__(self, num_hid=64, maxlen=100):\n",
    "        super().__init__()\n",
    "        self.conv1 = keras.layers.Conv1D(\n",
    "            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv2 = keras.layers.Conv1D(\n",
    "            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv3 = keras.layers.Conv1D(\n",
    "            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        return self.conv3(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ab14XhPRHCa"
   },
   "source": [
    "## Transformer Encoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SpEtRUFDRHCb"
   },
   "outputs": [],
   "source": [
    "\n",
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, feed_forward_dim, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [\n",
    "                #layers.Dense(feed_forward_dim, activation=\"relu\"),\n",
    "                #layers.Dense(embed_dim),\n",
    "                layers.SeparableConv1D(feed_forward_dim, 3, activation='relu', padding='same'),\n",
    "                layers.SeparableConv1D(embed_dim, 3, padding='same'),\n",
    "\n",
    "\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfsTgZ6vRHCb"
   },
   "source": [
    "## Transformer Decoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "LRksSL9oRHCc"
   },
   "outputs": [],
   "source": [
    "\n",
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, feed_forward_dim, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.self_att = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.enc_att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.self_dropout = layers.Dropout(0.5)\n",
    "        self.enc_dropout = layers.Dropout(0.1)\n",
    "        self.ffn_dropout = layers.Dropout(0.1)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(feed_forward_dim, activation=\"relu\"),\n",
    "                layers.Dense(embed_dim),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def causal_attention_mask(self, batch_size, n_dest, n_src, dtype):\n",
    "        \"\"\"Masks the upper half of the dot product matrix in self attention.\n",
    "\n",
    "        This prevents flow of information from future tokens to current token.\n",
    "        1's in the lower triangle, counting from the lower right corner.\n",
    "        \"\"\"\n",
    "        i = tf.range(n_dest)[:, None]\n",
    "        j = tf.range(n_src)\n",
    "        m = i >= j - n_src + n_dest\n",
    "        mask = tf.cast(m, dtype)\n",
    "        mask = tf.reshape(mask, [1, n_dest, n_src])\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)], 0\n",
    "        )\n",
    "        return tf.tile(mask, mult)\n",
    "\n",
    "    def call(self, enc_out, target):\n",
    "        input_shape = tf.shape(target)\n",
    "        batch_size = input_shape[0]\n",
    "        seq_len = input_shape[1]\n",
    "        causal_mask = self.causal_attention_mask(batch_size, seq_len, seq_len, tf.bool)\n",
    "        target_att = self.self_att(target, target, attention_mask=causal_mask)\n",
    "        target_norm = self.layernorm1(target + self.self_dropout(target_att))\n",
    "        enc_out = self.enc_att(target_norm, enc_out)\n",
    "        enc_out_norm = self.layernorm2(self.enc_dropout(enc_out) + target_norm)\n",
    "        ffn_out = self.ffn(enc_out_norm)\n",
    "        ffn_out_norm = self.layernorm3(enc_out_norm + self.ffn_dropout(ffn_out))\n",
    "        return ffn_out_norm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d55jG_L0RHCc"
   },
   "source": [
    "## Complete the Transformer model\n",
    "\n",
    "Our model takes audio spectrograms as inputs and predicts a sequence of characters.\n",
    "During training, we give the decoder the target character sequence shifted to the left\n",
    "as input. During inference, the decoder uses its own past predictions to predict the\n",
    "next token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "OgptmFnFRHCd"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_hid=64,\n",
    "        num_head=2,\n",
    "        num_feed_forward=128,\n",
    "        source_maxlen=100,\n",
    "        target_maxlen=100,\n",
    "        num_layers_enc=5,\n",
    "        num_layers_dec=3,\n",
    "        num_classes=10,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.loss_metric = tf.keras.metrics.Mean(name=\"loss\")\n",
    "        self.num_layers_enc = num_layers_enc\n",
    "        self.num_layers_dec = num_layers_dec\n",
    "        self.target_maxlen = target_maxlen\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.enc_input = SpeechFeatureEmbedding(num_hid=num_hid, maxlen=source_maxlen)\n",
    "        self.dec_input = TokenEmbedding(\n",
    "            num_vocab=num_classes, maxlen=target_maxlen, num_hid=num_hid\n",
    "        )\n",
    "\n",
    "        self.encoder = tf.keras.Sequential(\n",
    "            [self.enc_input]\n",
    "            + [\n",
    "                TransformerEncoder(num_hid, num_head, num_feed_forward)\n",
    "                for _ in range(num_layers_enc)\n",
    "            ]\n",
    "        )\n",
    "         #Comentar esta sequencia para treinar UA\n",
    "        for i in range(num_layers_dec):\n",
    "            setattr(\n",
    "                self,\n",
    "                f\"dec_layer_{i}\",\n",
    "                TransformerDecoder(num_hid, num_head, num_feed_forward),\n",
    "            )\n",
    "        \n",
    "        ####################### Congela todas as camadas decodificadoras ################################\n",
    "\n",
    "        #for i in range(num_layers_dec):\n",
    "        #    dec_layer = TransformerDecoder(num_hid, num_head, num_feed_forward)\n",
    "        #    dec_layer.trainable = False  # Congelar a camada\n",
    "        #    setattr(self, f\"dec_layer_{i}\", dec_layer)\n",
    "        #    print(dec_layer.name, dec_layer.trainable)\n",
    "            \n",
    "        ########################Congela apenas uma camada conforme o indice #############################\n",
    "        #\n",
    "        # Supondo que tenha 3 camadas de decodificador e queira congelar apenas a segunda camada\n",
    "        '''\n",
    "        for i in range(num_layers_dec):\n",
    "            dec_layer = TransformerDecoder(num_hid, num_head, num_feed_forward)\n",
    "            if i == 1:  # Se for a segunda camada (índice 1)\n",
    "                dec_layer.trainable = False  # Congelar a camada\n",
    "            setattr(self, f\"dec_layer_{i}\", dec_layer)\n",
    "        '''\n",
    "        #################################################################################################\n",
    "\n",
    "        self.classifier = layers.Dense(num_classes)\n",
    "\n",
    "    def decode(self, enc_out, target):\n",
    "        y = self.dec_input(target)\n",
    "        for i in range(self.num_layers_dec):\n",
    "            y = getattr(self, f\"dec_layer_{i}\")(enc_out, y)\n",
    "        return y\n",
    "\n",
    "    def call(self, inputs):\n",
    "        source = inputs[0]\n",
    "        target = inputs[1]\n",
    "        x = self.encoder(source)\n",
    "        y = self.decode(x, target)\n",
    "        return self.classifier(y)\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.loss_metric]\n",
    "    \n",
    "    def train_step(self, batch):\n",
    "        \"\"\"Processes one batch inside model.fit().\"\"\"\n",
    "        source = batch[\"source\"]\n",
    "        target = batch[\"target\"]\n",
    "        dec_input = target[:, :-1]\n",
    "        dec_target = target[:, 1:]\n",
    "        with tf.GradientTape() as tape:\n",
    "            preds = self([source, dec_input])\n",
    "            one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n",
    "            mask = tf.math.logical_not(tf.math.equal(dec_target, 0))\n",
    "            loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "            loss = loss_object(one_hot, preds, sample_weight=mask)\n",
    "\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        self.loss_metric.update_state(loss)\n",
    "        return {\"loss\": self.loss_metric.result()}\n",
    "\n",
    "    def test_step(self, batch):\n",
    "        source = batch[\"source\"]\n",
    "        target = batch[\"target\"]\n",
    "        dec_input = target[:, :-1]\n",
    "        dec_target = target[:, 1:]\n",
    "        preds = self([source, dec_input])\n",
    "        one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n",
    "        mask = tf.math.logical_not(tf.math.equal(dec_target, 0))\n",
    "        loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "        loss = loss_object(one_hot, preds, sample_weight=mask)\n",
    "\n",
    "        self.loss_metric.update_state(loss)\n",
    "        return {\"loss\": self.loss_metric.result()}\n",
    "\n",
    "    def generate(self, source, target_start_token_idx):\n",
    "        \"\"\"Performs inference over one batch of inputs using greedy decoding.\"\"\"\n",
    "        bs = tf.shape(source)[0]\n",
    "        enc = self.encoder(source)\n",
    "        dec_input = tf.ones((bs, 1), dtype=tf.int32) * target_start_token_idx\n",
    "        dec_logits = []\n",
    "        for i in range(self.target_maxlen - 1):\n",
    "            dec_out = self.decode(enc, dec_input)\n",
    "            logits = self.classifier(dec_out)\n",
    "            logits = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
    "            last_logit = tf.expand_dims(logits[:, -1], axis=-1)\n",
    "            dec_logits.append(last_logit)\n",
    "            dec_input = tf.concat([dec_input, last_logit], axis=-1)\n",
    "        return dec_input\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "liuKciSRRHCd"
   },
   "source": [
    "## Download the dataset LJSpeech\n",
    "\n",
    "Note: This requires ~3.6 GB of disk space and\n",
    "takes ~5 minutes for the extraction of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "au3uVjM1RHCd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "keras.utils.get_file(\n",
    "    os.path.join(os.getcwd(), \"data.tar.gz\"),\n",
    "    \"https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\",\n",
    "    extract=True,\n",
    "    archive_format=\"tar\",\n",
    "    cache_dir=\".\",\n",
    ")\n",
    "'''\n",
    "\n",
    "saveto = \".\\\\datasets\\\\LJSpeech-1.1\"\n",
    "wavs = glob(\"{}\\\\**\\\\*.wav\".format(saveto), recursive=True)\n",
    "#print(wavs)\n",
    "id_to_text = {}\n",
    "with open(os.path.join(saveto, \"metadata.csv\"), encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        id = line.strip().split(\"|\")[0]\n",
    "        text = line.strip().split(\"|\")[2]\n",
    "        id_to_text[id] = text\n",
    "\n",
    "\n",
    "def get_data(wavs, id_to_text, maxlen=50):\n",
    "    \"\"\"returns mapping of audio paths and transcription texts\"\"\"\n",
    "    data = []\n",
    "    for w in wavs:\n",
    "        id = w.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "        if len(id_to_text[id]) < maxlen:\n",
    "            data.append({\"audio\": w, \"text\": id_to_text[id]})\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset UA-Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "au3uVjM1RHCd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "keras.utils.get_file(\n",
    "    os.path.join(os.getcwd(), \"data.tar.gz\"),\n",
    "    \"https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\",\n",
    "    extract=True,\n",
    "    archive_format=\"tar\",\n",
    "    cache_dir=\".\",\n",
    ")\n",
    "'''\n",
    "\n",
    "#saveto = \".\\\\datasets\\\\LJSpeech-1.1\"\n",
    "saveto = '.\\\\datasets\\\\uaspeech\\\\wavs'\n",
    "wavs = glob(\"{}\\\\**\\\\*.wav\".format(saveto), recursive=True)\n",
    "id_to_text = {}\n",
    "with open(os.path.join(saveto, \".\\\\transcript\\metadata.csv\"), encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        id = line.strip().split(\"|\")[0]\n",
    "        text = line.strip().split(\"|\")[1]\n",
    "        id_to_text[id] = text\n",
    "\n",
    "saveto_test = '.\\\\datasets\\\\uaspeech\\\\test'\n",
    "wavs_test = glob(\"{}\\\\**\\\\*.wav\".format(saveto_test), recursive=True)\n",
    "id_to_text_test = {}\n",
    "with open(os.path.join(saveto_test, \".\\\\transcript\\metadata.csv\"), encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        id_test = line.strip().split(\"|\")[0]\n",
    "        text_test = line.strip().split(\"|\")[1]\n",
    "        id_to_text_test[id_test] = text_test       \n",
    "\n",
    "def get_random_files(wavs, percentage):\n",
    "    num_files = len(wavs)\n",
    "    num_samples = int(num_files * percentage)\n",
    "    return random.sample(wavs, num_samples)\n",
    "\n",
    "def get_data(wavs, id_to_text, maxlen=50, percentage=0.05):\n",
    "    \"\"\"returns mapping of audio paths and transcription texts\"\"\"\n",
    "    data = []\n",
    "    for subdir in wavs:\n",
    "        # Lista de arquivos de áudio no subdiretório atual\n",
    "        files_in_subdir = glob(os.path.join(subdir, \"*.wav\"))\n",
    "        # Selecionar aleatoriamente 5% dos arquivos\n",
    "        selected_files = get_random_files(files_in_subdir, percentage)\n",
    "        for file_path in selected_files:\n",
    "            id = os.path.basename(file_path).split(\".\")[0]\n",
    "            if id in id_to_text and len(id_to_text[id]) < maxlen:\n",
    "                data.append({\"audio\": file_path, \"text\": id_to_text[id]})\n",
    "    return data\n",
    "        \n",
    "''' ######## Original ################\n",
    "def get_data(wavs, id_to_text, maxlen=50):\n",
    "    \n",
    "    \"\"\"returns mapping of audio paths and transcription texts\"\"\"\n",
    "    data = []\n",
    "    for w in wavs:\n",
    "        id = w.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "        if len(id_to_text[id]) < maxlen:\n",
    "            data.append({\"audio\": w, \"text\": id_to_text[id]})\n",
    "    return data\n",
    "    '''\n",
    "\n",
    "def get_data_test(wavs_test, id_to_text_test, maxlen=50):\n",
    "    \"\"\"returns mapping of audio paths and transcription texts\"\"\"\n",
    "    data_test = []\n",
    "    for w in wavs_test:\n",
    "        id_test = w.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "        if len(id_to_text_test[id_test]) < maxlen:\n",
    "            data_test.append({\"audio\": w, \"text\": id_to_text_test[id_test]})\n",
    "    return data_test\n",
    "\n",
    "print(get_data(wavs, id_to_text, maxlen=50, percentage=0.05)[1:5])\n",
    "print(get_data_test(wavs_test, id_to_text_test, maxlen=50)[1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_data(wavs, id_to_text, maxlen=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4eTa9km4RHCe"
   },
   "source": [
    "## Preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "2mxWQLOARHCe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size 34\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class VectorizeChar:\n",
    "    def __init__(self, max_len=50):\n",
    "        self.vocab = (\n",
    "            [\"-\", \"#\", \"<\", \">\"]\n",
    "            + [chr(i + 96) for i in range(1, 27)]\n",
    "            + [\" \", \".\", \",\", \"?\"]\n",
    "        )\n",
    "        self.max_len = max_len\n",
    "        self.char_to_idx = {}\n",
    "        for i, ch in enumerate(self.vocab):\n",
    "            self.char_to_idx[ch] = i\n",
    "\n",
    "    def __call__(self, text):\n",
    "        text = text.lower()\n",
    "        text = text[: self.max_len - 2]\n",
    "        text = \"<\" + text + \">\"\n",
    "        pad_len = self.max_len - len(text)\n",
    "        return [self.char_to_idx.get(ch, 1) for ch in text] + [0] * pad_len\n",
    "\n",
    "    def get_vocabulary(self):\n",
    "        return self.vocab\n",
    "\n",
    "\n",
    "max_target_len = 200  # all transcripts in out data are < 200 characters\n",
    "data = get_data(wavs, id_to_text, max_target_len)\n",
    "#data = get_data(wavs, id_to_text, max_target_len, percentage=0.05) # para UASPEECH - comentar linha superior\n",
    "#data_test = get_data_test(wavs_test, id_to_text_test, max_target_len) para UASPEECH\n",
    "vectorizer = VectorizeChar(max_target_len)\n",
    "vocab_size = len(vectorizer.get_vocabulary())\n",
    "print(\"vocab size\", len(vectorizer.get_vocabulary()))\n",
    "\n",
    "\n",
    "def create_text_ds(data):\n",
    "    texts = [_[\"text\"] for _ in data]\n",
    "    text_ds = [vectorizer(t) for t in texts]\n",
    "    text_ds = tf.data.Dataset.from_tensor_slices(text_ds)\n",
    "    return text_ds\n",
    "\n",
    "\n",
    "def path_to_audio(path):\n",
    "    # spectrogram using stft\n",
    "    audio = tf.io.read_file(path)\n",
    "    audio, _ = tf.audio.decode_wav(audio, 1)\n",
    "    audio = tf.squeeze(audio, axis=-1)\n",
    "    stfts = tf.signal.stft(audio, frame_length=200, frame_step=80, fft_length=256)\n",
    "    x = tf.math.pow(tf.abs(stfts), 0.5)\n",
    "    # normalisation\n",
    "    means = tf.math.reduce_mean(x, 1, keepdims=True)\n",
    "    stddevs = tf.math.reduce_std(x, 1, keepdims=True)\n",
    "    x = (x - means) / stddevs\n",
    "    audio_len = tf.shape(x)[0]\n",
    "    # padding to 10 seconds\n",
    "    pad_len = 2754\n",
    "    paddings = tf.constant([[0, pad_len], [0, 0]])\n",
    "    x = tf.pad(x, paddings, \"CONSTANT\")[:pad_len, :]\n",
    "    return x\n",
    "\n",
    "\n",
    "def create_audio_ds(data):\n",
    "    flist = [_[\"audio\"] for _ in data]\n",
    "    audio_ds = tf.data.Dataset.from_tensor_slices(flist)\n",
    "    audio_ds = audio_ds.map(path_to_audio, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return audio_ds\n",
    "\n",
    "\n",
    "def create_tf_dataset(data, bs=64):\n",
    "    audio_ds = create_audio_ds(data)\n",
    "    text_ds = create_text_ds(data)\n",
    "    ds = tf.data.Dataset.zip((audio_ds, text_ds))\n",
    "    ds = ds.map(lambda x, y: {\"source\": x, \"target\": y})\n",
    "    ds = ds.batch(bs)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(len(data) * 0.99) # comentar para UA\n",
    "train_data = data[:split] # comentar para UA\n",
    "train_data = data\n",
    "test_data = data[split:] # comentar para UA\n",
    "#test_data = data_test # Para UA\n",
    "ds = create_tf_dataset(train_data, bs=64)\n",
    "val_ds = create_tf_dataset(test_data, bs=4) #orig. = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset shapes: {source: (None, None, 129), target: (None, 200)}, types: {source: tf.float32, target: tf.int32}>\n"
     ]
    }
   ],
   "source": [
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset shapes: {source: (None, None, 129), target: (None, 200)}, types: {source: tf.float32, target: tf.int32}>\n"
     ]
    }
   ],
   "source": [
    "print(val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "szBaODmsRHCg"
   },
   "source": [
    "## Callbacks to display predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "1L-YvvMxRHCg"
   },
   "outputs": [],
   "source": [
    "\n",
    "class DisplayOutputs(keras.callbacks.Callback):\n",
    "    def __init__(\n",
    "        self, batch, idx_to_token, target_start_token_idx=27, target_end_token_idx=28\n",
    "    ):\n",
    "        \"\"\"Displays a batch of outputs after every epoch\n",
    "\n",
    "        Args:\n",
    "            batch: A test batch containing the keys \"source\" and \"target\"\n",
    "            idx_to_token: A List containing the vocabulary tokens corresponding to their indices\n",
    "            target_start_token_idx: A start token index in the target vocabulary\n",
    "            target_end_token_idx: An end token index in the target vocabulary\n",
    "        \"\"\"\n",
    "        self.batch = batch\n",
    "        self.target_start_token_idx = target_start_token_idx\n",
    "        self.target_end_token_idx = target_end_token_idx\n",
    "        self.idx_to_char = idx_to_token\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % 5 != 0:\n",
    "            return\n",
    "        source = self.batch[\"source\"]\n",
    "        target = self.batch[\"target\"].numpy()\n",
    "        bs = tf.shape(source)[0]\n",
    "        preds = self.model.generate(source, self.target_start_token_idx)\n",
    "        preds = preds.numpy()\n",
    "        for i in range(bs):\n",
    "            target_text = \"\".join([self.idx_to_char[_] for _ in target[i, :]])\n",
    "            prediction = \"\"\n",
    "            for idx in preds[i, :]:\n",
    "                prediction += self.idx_to_char[idx]\n",
    "                if idx == self.target_end_token_idx:\n",
    "                    break\n",
    "            print(f\"target:     {target_text.replace('-','')}\")\n",
    "            print(f\"prediction: {prediction}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6JfOL_oARHCg"
   },
   "source": [
    "## Learning rate schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "D-dRLFkNRHCh"
   },
   "outputs": [],
   "source": [
    "\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        init_lr=0.00001,\n",
    "        lr_after_warmup=0.001,\n",
    "        final_lr=0.00001,\n",
    "        warmup_epochs=15,\n",
    "        decay_epochs=85,\n",
    "        steps_per_epoch=203,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.init_lr = init_lr\n",
    "        self.lr_after_warmup = lr_after_warmup\n",
    "        self.final_lr = final_lr\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.decay_epochs = decay_epochs\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "\n",
    "    def calculate_lr(self, epoch):\n",
    "        \"\"\"linear warm up - linear decay\"\"\"\n",
    "        warmup_lr = (\n",
    "            self.init_lr\n",
    "            + ((self.lr_after_warmup - self.init_lr) / (self.warmup_epochs - 1)) * epoch\n",
    "        )\n",
    "        decay_lr = tf.math.maximum(\n",
    "            self.final_lr,\n",
    "            self.lr_after_warmup\n",
    "            - (epoch - self.warmup_epochs)\n",
    "            * (self.lr_after_warmup - self.final_lr)\n",
    "            / self.decay_epochs,\n",
    "        )\n",
    "        return tf.math.minimum(warmup_lr, decay_lr)\n",
    "\n",
    "    def __call__(self, step):\n",
    "        epoch = step // self.steps_per_epoch\n",
    "        epoch = tf.cast(epoch, \"float32\")\n",
    "        return self.calculate_lr(epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ne33ZwMORHCh"
   },
   "source": [
    "## Create & train the end-to-end model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salva e carrega o modelo"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def create_callbacks(display_cb, filepath):\n",
    "    # Função para salvar o melhor modelo baseado na perda de validação\n",
    "    model_checkpoint_callback = ModelCheckpoint(\n",
    "        filepath=filepath,\n",
    "        save_weights_only=True,\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_best_only=True)\n",
    "\n",
    "    # Adicione model_checkpoint_callback à lista de callbacks.\n",
    "    callbacks_list = [display_cb, model_checkpoint_callback]\n",
    "    return callbacks_list"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def load_checkpoint(checkpoint, checkpoint_manager):\n",
    "    # Função para retomar o treinamento de onde parou\n",
    "    checkpoint.restore(checkpoint_manager.latest_checkpoint)\n",
    "    if checkpoint_manager.latest_checkpoint:\n",
    "        print(\"Restaurado de {}\".format(checkpoint_manager.latest_checkpoint))\n",
    "    else:\n",
    "        print(\"Inicializando do zero.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "bby6svtcRHCh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicializando do zero.\n",
      "Epoch 1/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.5391target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the alithe t t t o ar t at the t t the t io s the t t the te te the e the t t t othe te the at thee t te t te ten the an oe o the the e the the the e the te the the the the t a the the the te te t t \n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <the a t the the t t the at the o t the t io s the t t the te the t are t t t in othe the the t thee t te t te ten the the an the te t e the the the o the the the ore t te t t a the the the te te t t \n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <the alithe t t t o ar t at the t t the t io s the t t the te te the e the t t t othe te the at thee t te t te ten the an oe o the the e the the the e the te the the the the t a the the the te te t t \n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <the a t the the t t the at the o t the t io s the t t the te the t are t t t in othe the the t thee t te t te ten the the an the te t e the the the o t t the the ore t te t t a the the the te te t t \n",
      "\n",
      "\n",
      "Epoch 00001: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 136s 609ms/step - loss: 1.5391 - val_loss: 1.4841\n",
      "Epoch 2/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.2508\n",
      "Epoch 00002: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 568ms/step - loss: 1.2508 - val_loss: 1.2777\n",
      "Epoch 3/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.1862\n",
      "Epoch 00003: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 569ms/step - loss: 1.1862 - val_loss: 1.2195\n",
      "Epoch 4/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.1032\n",
      "Epoch 00004: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 569ms/step - loss: 1.1032 - val_loss: 1.0876\n",
      "Epoch 5/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.0181\n",
      "Epoch 00005: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 118s 572ms/step - loss: 1.0181 - val_loss: 0.9939\n",
      "Epoch 6/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.9533target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the secres and the secres and and and and and and and and the president the secret>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <the secres as and and the secre and and and and and and and and the secre and and the secres and and and and the seconsident of the president the presece.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <the secres of the secres asssinal and and the secres>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <the secres of the sevence of the secre and and and and and and and and and the secre and and and and and and and the secres of the proulde.>\n",
      "\n",
      "\n",
      "Epoch 00006: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 125s 610ms/step - loss: 0.9533 - val_loss: 0.9084\n",
      "Epoch 7/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.8913\n",
      "Epoch 00007: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 570ms/step - loss: 0.8913 - val_loss: 0.8083\n",
      "Epoch 8/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.8081\n",
      "Epoch 00008: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 119s 580ms/step - loss: 0.8081 - val_loss: 0.6880\n",
      "Epoch 9/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.6648\n",
      "Epoch 00009: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 118s 574ms/step - loss: 0.6648 - val_loss: 0.4655\n",
      "Epoch 10/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.4641\n",
      "Epoch 00010: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 119s 578ms/step - loss: 0.4641 - val_loss: 0.2900\n",
      "Epoch 11/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.3339target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the incromation supplied by other agencies will be wasted.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <present than the present you gress must develop the capasited basite the vellop the could as must than the present jubects on amore suffice becrative been.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present mannial the final the finaling sistem is obseley t.>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it maxines were altments world, and inother officent nother governmen officent abolowment exas no and in other government officence world whide leas.>\n",
      "\n",
      "\n",
      "Epoch 00011: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 127s 619ms/step - loss: 0.3339 - val_loss: 0.1995\n",
      "Epoch 12/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.2633\n",
      "Epoch 00012: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 571ms/step - loss: 0.2633 - val_loss: 0.1473\n",
      "Epoch 13/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.2188\n",
      "Epoch 00013: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 118s 572ms/step - loss: 0.2188 - val_loss: 0.1189\n",
      "Epoch 14/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.1913\n",
      "Epoch 00014: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 571ms/step - loss: 0.1913 - val_loss: 0.1019\n",
      "Epoch 15/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.1713\n",
      "Epoch 00015: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 120s 585ms/step - loss: 0.1713 - val_loss: 0.0865\n",
      "Epoch 16/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.1511target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the increased information supplied by other agencies will be wasted.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <prs must develop the copasity to classify its on a more suffice smust than the present jubelop the couph the couph the couph the coto classificie agraphic belop the cupasitie t t to thevemeam>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present manual filey system is obsoly t.>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it makes no used in the business were old an other government officessing which of the recent developments in the bused in the bused in the business.>\n",
      "\n",
      "\n",
      "Epoch 00016: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 132s 642ms/step - loss: 0.1511 - val_loss: 0.0718\n",
      "Epoch 17/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.1347\n",
      "Epoch 00017: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 118s 574ms/step - loss: 0.1347 - val_loss: 0.0629\n",
      "Epoch 18/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.1238\n",
      "Epoch 00018: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 118s 572ms/step - loss: 0.1238 - val_loss: 0.0542\n",
      "Epoch 19/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.1106\n",
      "Epoch 00019: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 119s 577ms/step - loss: 0.1106 - val_loss: 0.0486\n",
      "Epoch 20/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.1020\n",
      "Epoch 00020: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 119s 577ms/step - loss: 0.1020 - val_loss: 0.0441\n",
      "Epoch 21/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0932target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the increased information supplied by other agencies will be wasted.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <prs must to velop the copassify its subjects on a more sufficicated basis than the present geographic breaked one.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present manual v.iling system is obsoly t.>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it makes no use of the recent developments in the busiden the business werelled and in other government offices.>\n",
      "\n",
      "\n",
      "Epoch 00021: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 127s 617ms/step - loss: 0.0932 - val_loss: 0.0397\n",
      "Epoch 22/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0859\n",
      "Epoch 00022: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 570ms/step - loss: 0.0859 - val_loss: 0.0367\n",
      "Epoch 23/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0799\n",
      "Epoch 00023: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 568ms/step - loss: 0.0799 - val_loss: 0.0330\n",
      "Epoch 24/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0745\n",
      "Epoch 00024: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 571ms/step - loss: 0.0745 - val_loss: 0.0280\n",
      "Epoch 25/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0711\n",
      "Epoch 00025: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 568ms/step - loss: 0.0711 - val_loss: 0.0261\n",
      "Epoch 26/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0660target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the increased information supplied by other agencies will be wasted.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <prs must than the present geographic break break down#t then the present geographic breate down.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present manual filling system is obsolely tw.>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it makes no use of the recent developments in automatic developments in the business world and in other government offices.>\n",
      "\n",
      "\n",
      "Epoch 00026: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 127s 618ms/step - loss: 0.0660 - val_loss: 0.0236\n",
      "Epoch 27/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0622\n",
      "Epoch 00027: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 118s 575ms/step - loss: 0.0622 - val_loss: 0.0247\n",
      "Epoch 28/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0605\n",
      "Epoch 00028: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 118s 575ms/step - loss: 0.0605 - val_loss: 0.0228\n",
      "Epoch 29/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0569\n",
      "Epoch 00029: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 118s 575ms/step - loss: 0.0569 - val_loss: 0.0205\n",
      "Epoch 30/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0540\n",
      "Epoch 00030: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 119s 580ms/step - loss: 0.0540 - val_loss: 0.0188\n",
      "Epoch 31/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0502target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the increaced information supplied by other agencies will be wasted.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <prs must develop the capacity to classify its subjects on a more suphisticated basis than the present geographic breakdown.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present manual filing system is obsolight.>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it makes no use of the recent davelopments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "\n",
      "\n",
      "Epoch 00031: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 129s 626ms/step - loss: 0.0502 - val_loss: 0.0180\n",
      "Epoch 32/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0482\n",
      "Epoch 00032: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 568ms/step - loss: 0.0482 - val_loss: 0.0160\n",
      "Epoch 33/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0458\n",
      "Epoch 00033: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 118s 572ms/step - loss: 0.0458 - val_loss: 0.0149\n",
      "Epoch 34/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0432\n",
      "Epoch 00034: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 571ms/step - loss: 0.0432 - val_loss: 0.0138\n",
      "Epoch 35/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0413\n",
      "Epoch 00035: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 571ms/step - loss: 0.0413 - val_loss: 0.0154\n",
      "Epoch 36/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0400target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the increased information supplied by other agencies will be wasted.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breated basis than the present geographycdom.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present manual filing system is obsolitant manual filing system is ubsolelet.>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "\n",
      "\n",
      "Epoch 00036: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 126s 615ms/step - loss: 0.0400 - val_loss: 0.0129\n",
      "Epoch 37/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0390\n",
      "Epoch 00037: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 116s 564ms/step - loss: 0.0390 - val_loss: 0.0122\n",
      "Epoch 38/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0348\n",
      "Epoch 00038: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 116s 566ms/step - loss: 0.0348 - val_loss: 0.0102\n",
      "Epoch 39/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0334\n",
      "Epoch 00039: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 116s 565ms/step - loss: 0.0334 - val_loss: 0.0089\n",
      "Epoch 40/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0318\n",
      "Epoch 00040: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 116s 565ms/step - loss: 0.0318 - val_loss: 0.0087\n",
      "Epoch 41/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0293target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the increased information supplied by other agencies will be wasted.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <prs must develop the capacity to clasify its subjects on a more so fice its than the present geographic breakdown.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present manual filing system is obsolete,>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "\n",
      "\n",
      "Epoch 00041: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 125s 606ms/step - loss: 0.0293 - val_loss: 0.0093\n",
      "Epoch 42/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0286\n",
      "Epoch 00042: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 116s 565ms/step - loss: 0.0286 - val_loss: 0.0083\n",
      "Epoch 43/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0270\n",
      "Epoch 00043: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 118s 576ms/step - loss: 0.0270 - val_loss: 0.0071\n",
      "Epoch 44/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0264\n",
      "Epoch 00044: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 569ms/step - loss: 0.0264 - val_loss: 0.0068\n",
      "Epoch 45/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0252\n",
      "Epoch 00045: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 571ms/step - loss: 0.0252 - val_loss: 0.0057\n",
      "Epoch 46/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0230target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the increased information supplied by other agencies will be wasted.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present manual filing system is obsolete#>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it makes no use of the recent developments in automatic data processing which are widely used in the business world and din other government offices.>\n",
      "\n",
      "\n",
      "Epoch 00046: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 126s 611ms/step - loss: 0.0230 - val_loss: 0.0054\n",
      "Epoch 47/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0219\n",
      "Epoch 00047: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 116s 565ms/step - loss: 0.0219 - val_loss: 0.0062\n",
      "Epoch 48/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0256\n",
      "Epoch 00048: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 567ms/step - loss: 0.0256 - val_loss: 0.0064\n",
      "Epoch 49/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0201\n",
      "Epoch 00049: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 118s 574ms/step - loss: 0.0201 - val_loss: 0.0057\n",
      "Epoch 50/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0177\n",
      "Epoch 00050: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 119s 580ms/step - loss: 0.0177 - val_loss: 0.0051\n",
      "Epoch 51/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0162target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the increased information supplied by other agencies will be wasted.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present manual filing system is obsolete#>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "\n",
      "\n",
      "Epoch 00051: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 126s 615ms/step - loss: 0.0162 - val_loss: 0.0034\n",
      "Epoch 52/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0161\n",
      "Epoch 00052: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 118s 575ms/step - loss: 0.0161 - val_loss: 0.0038\n",
      "Epoch 53/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0169\n",
      "Epoch 00053: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 118s 572ms/step - loss: 0.0169 - val_loss: 0.0044\n",
      "Epoch 54/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0165\n",
      "Epoch 00054: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 118s 572ms/step - loss: 0.0165 - val_loss: 0.0028\n",
      "Epoch 55/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0143\n",
      "Epoch 00055: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 118s 572ms/step - loss: 0.0143 - val_loss: 0.0029\n",
      "Epoch 56/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0129target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the increased information supplied by other agencies will be wasted.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present manual filing system is obsolete#>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "\n",
      "\n",
      "Epoch 00056: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 128s 622ms/step - loss: 0.0129 - val_loss: 0.0023\n",
      "Epoch 57/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0160\n",
      "Epoch 00057: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 119s 579ms/step - loss: 0.0160 - val_loss: 0.0048\n",
      "Epoch 58/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0143\n",
      "Epoch 00058: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 119s 579ms/step - loss: 0.0143 - val_loss: 0.0024\n",
      "Epoch 59/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0098\n",
      "Epoch 00059: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 120s 582ms/step - loss: 0.0098 - val_loss: 0.0019\n",
      "Epoch 60/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0087\n",
      "Epoch 00060: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 118s 575ms/step - loss: 0.0087 - val_loss: 0.0014\n",
      "Epoch 61/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0087target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the increased information supplied by other agencies will be wasted.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present manual filing system is obsolete#>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "\n",
      "\n",
      "Epoch 00061: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 131s 640ms/step - loss: 0.0087 - val_loss: 0.0018\n",
      "Epoch 62/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0085\n",
      "Epoch 00062: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 124s 605ms/step - loss: 0.0085 - val_loss: 0.0020\n",
      "Epoch 63/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0082\n",
      "Epoch 00063: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 124s 604ms/step - loss: 0.0082 - val_loss: 0.0014\n",
      "Epoch 64/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0078\n",
      "Epoch 00064: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 120s 582ms/step - loss: 0.0078 - val_loss: 0.0017\n",
      "Epoch 65/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 00065: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 116s 566ms/step - loss: 0.0070 - val_loss: 0.0014\n",
      "Epoch 66/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0066target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the increased information supplied by other agencies will be wasted.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present manual filing system is obsolete#>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "\n",
      "\n",
      "Epoch 00066: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 126s 612ms/step - loss: 0.0066 - val_loss: 0.0011\n",
      "Epoch 67/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0079\n",
      "Epoch 00067: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 116s 566ms/step - loss: 0.0079 - val_loss: 0.0012\n",
      "Epoch 68/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0060\n",
      "Epoch 00068: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 571ms/step - loss: 0.0060 - val_loss: 0.0011\n",
      "Epoch 69/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 00069: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 569ms/step - loss: 0.0054 - val_loss: 0.0013\n",
      "Epoch 70/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 00070: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 569ms/step - loss: 0.0049 - val_loss: 7.0552e-04\n",
      "Epoch 71/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0046target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the increased information supplied by other agencies will be wasted.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present manual filing system is obsolete#>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "\n",
      "\n",
      "Epoch 00071: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 126s 612ms/step - loss: 0.0046 - val_loss: 6.9674e-04\n",
      "Epoch 72/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 00072: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 119s 578ms/step - loss: 0.0041 - val_loss: 6.9115e-04\n",
      "Epoch 73/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 00073: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 571ms/step - loss: 0.0036 - val_loss: 4.5850e-04\n",
      "Epoch 74/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 00074: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 119s 579ms/step - loss: 0.0034 - val_loss: 5.6023e-04\n",
      "Epoch 75/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 00075: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 570ms/step - loss: 0.0033 - val_loss: 6.9709e-04\n",
      "Epoch 76/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0035target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the increased information supplied by other agencies will be wasted.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present manual filing system is obsolete#>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "\n",
      "\n",
      "Epoch 00076: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 127s 617ms/step - loss: 0.0035 - val_loss: 4.7347e-04\n",
      "Epoch 77/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 00077: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 567ms/step - loss: 0.0032 - val_loss: 4.1325e-04\n",
      "Epoch 78/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 00078: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 568ms/step - loss: 0.0029 - val_loss: 4.9567e-04\n",
      "Epoch 79/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0023\n",
      "Epoch 00079: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 118s 575ms/step - loss: 0.0023 - val_loss: 3.6522e-04\n",
      "Epoch 80/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0023\n",
      "Epoch 00080: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 571ms/step - loss: 0.0023 - val_loss: 2.6437e-04\n",
      "Epoch 81/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0022target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the increased information supplied by other agencies will be wasted.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present manual filing system is obsolete#>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "\n",
      "\n",
      "Epoch 00081: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 126s 612ms/step - loss: 0.0022 - val_loss: 4.1802e-04\n",
      "Epoch 82/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0019\n",
      "Epoch 00082: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 116s 564ms/step - loss: 0.0019 - val_loss: 3.8682e-04\n",
      "Epoch 83/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0017\n",
      "Epoch 00083: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 572ms/step - loss: 0.0017 - val_loss: 2.3596e-04\n",
      "Epoch 84/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0015\n",
      "Epoch 00084: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 567ms/step - loss: 0.0015 - val_loss: 2.1568e-04\n",
      "Epoch 85/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 0.0011\n",
      "Epoch 00085: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 571ms/step - loss: 0.0011 - val_loss: 1.6248e-04\n",
      "Epoch 86/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 8.2168e-04target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the increased information supplied by other agencies will be wasted.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present manual filing system is obsolete#>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "\n",
      "\n",
      "Epoch 00086: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 125s 608ms/step - loss: 8.2168e-04 - val_loss: 1.4889e-04\n",
      "Epoch 87/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 7.0661e-04\n",
      "Epoch 00087: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 119s 578ms/step - loss: 7.0661e-04 - val_loss: 1.5542e-04\n",
      "Epoch 88/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 5.9840e-04\n",
      "Epoch 00088: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 118s 572ms/step - loss: 5.9840e-04 - val_loss: 8.8973e-05\n",
      "Epoch 89/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 5.2589e-04\n",
      "Epoch 00089: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 119s 577ms/step - loss: 5.2589e-04 - val_loss: 8.9008e-05\n",
      "Epoch 90/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 4.3976e-04\n",
      "Epoch 00090: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 119s 580ms/step - loss: 4.3976e-04 - val_loss: 7.4988e-05\n",
      "Epoch 91/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 2.8508e-04target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the increased information supplied by other agencies will be wasted.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present manual filing system is obsolete#>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "\n",
      "\n",
      "Epoch 00091: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 125s 610ms/step - loss: 2.8508e-04 - val_loss: 4.7227e-05\n",
      "Epoch 92/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 2.0662e-04\n",
      "Epoch 00092: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 118s 572ms/step - loss: 2.0662e-04 - val_loss: 4.0161e-05\n",
      "Epoch 93/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.3322e-04\n",
      "Epoch 00093: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 119s 581ms/step - loss: 1.3322e-04 - val_loss: 3.2936e-05\n",
      "Epoch 94/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 7.8185e-05\n",
      "Epoch 00094: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 571ms/step - loss: 7.8185e-05 - val_loss: 2.6660e-05\n",
      "Epoch 95/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 5.9425e-05\n",
      "Epoch 00095: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 569ms/step - loss: 5.9425e-05 - val_loss: 2.5599e-05\n",
      "Epoch 96/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 4.4579e-05target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the increased information supplied by other agencies will be wasted.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present manual filing system is obsolete#>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "\n",
      "\n",
      "Epoch 00096: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 128s 621ms/step - loss: 4.4579e-05 - val_loss: 2.3255e-05\n",
      "Epoch 97/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 3.5738e-05\n",
      "Epoch 00097: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 118s 572ms/step - loss: 3.5738e-05 - val_loss: 2.2072e-05\n",
      "Epoch 98/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 3.0254e-05\n",
      "Epoch 00098: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 570ms/step - loss: 3.0254e-05 - val_loss: 2.1699e-05\n",
      "Epoch 99/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 2.7493e-05\n",
      "Epoch 00099: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 118s 572ms/step - loss: 2.7493e-05 - val_loss: 2.0841e-05\n",
      "Epoch 100/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 2.5544e-05\n",
      "Epoch 00100: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 118s 574ms/step - loss: 2.5544e-05 - val_loss: 2.0269e-05\n",
      "Epoch 101/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 2.4639e-05target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the increased information supplied by other agencies will be wasted.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present manual filing system is obsolete#>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "\n",
      "\n",
      "Epoch 00101: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 128s 623ms/step - loss: 2.4639e-05 - val_loss: 2.0073e-05\n",
      "Epoch 102/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 2.4251e-05\n",
      "Epoch 00102: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 116s 566ms/step - loss: 2.4251e-05 - val_loss: 1.9756e-05\n",
      "Epoch 103/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 2.3861e-05\n",
      "Epoch 00103: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 571ms/step - loss: 2.3861e-05 - val_loss: 1.9356e-05\n",
      "Epoch 104/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 2.3460e-05\n",
      "Epoch 00104: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 116s 565ms/step - loss: 2.3460e-05 - val_loss: 1.8915e-05\n",
      "Epoch 105/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 2.3045e-05\n",
      "Epoch 00105: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 118s 573ms/step - loss: 2.3045e-05 - val_loss: 1.8449e-05\n",
      "Epoch 106/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 2.2614e-05target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the increased information supplied by other agencies will be wasted.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present manual filing system is obsolete#>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "\n",
      "\n",
      "Epoch 00106: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 126s 613ms/step - loss: 2.2614e-05 - val_loss: 1.7973e-05\n",
      "Epoch 107/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 2.2165e-05\n",
      "Epoch 00107: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 570ms/step - loss: 2.2165e-05 - val_loss: 1.7485e-05\n",
      "Epoch 108/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 2.1700e-05\n",
      "Epoch 00108: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 568ms/step - loss: 2.1700e-05 - val_loss: 1.6992e-05\n",
      "Epoch 109/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 2.1219e-05\n",
      "Epoch 00109: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 570ms/step - loss: 2.1219e-05 - val_loss: 1.6492e-05\n",
      "Epoch 110/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 2.0722e-05\n",
      "Epoch 00110: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 119s 580ms/step - loss: 2.0722e-05 - val_loss: 1.5988e-05\n",
      "Epoch 111/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 2.0209e-05target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the increased information supplied by other agencies will be wasted.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present manual filing system is obsolete#>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "\n",
      "\n",
      "Epoch 00111: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 126s 612ms/step - loss: 2.0209e-05 - val_loss: 1.5480e-05\n",
      "Epoch 112/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.9683e-05\n",
      "Epoch 00112: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 567ms/step - loss: 1.9683e-05 - val_loss: 1.4970e-05\n",
      "Epoch 113/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.9143e-05\n",
      "Epoch 00113: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 571ms/step - loss: 1.9143e-05 - val_loss: 1.4459e-05\n",
      "Epoch 114/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.8591e-05\n",
      "Epoch 00114: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 569ms/step - loss: 1.8591e-05 - val_loss: 1.3943e-05\n",
      "Epoch 115/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.8030e-05\n",
      "Epoch 00115: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 116s 565ms/step - loss: 1.8030e-05 - val_loss: 1.3432e-05\n",
      "Epoch 116/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.7460e-05target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the increased information supplied by other agencies will be wasted.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present manual filing system is obsolete#>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "\n",
      "\n",
      "Epoch 00116: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 125s 609ms/step - loss: 1.7460e-05 - val_loss: 1.2923e-05\n",
      "Epoch 117/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.6882e-05\n",
      "Epoch 00117: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 567ms/step - loss: 1.6882e-05 - val_loss: 1.2419e-05\n",
      "Epoch 118/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.6300e-05\n",
      "Epoch 00118: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 116s 564ms/step - loss: 1.6300e-05 - val_loss: 1.1918e-05\n",
      "Epoch 119/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.5713e-05\n",
      "Epoch 00119: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 116s 566ms/step - loss: 1.5713e-05 - val_loss: 1.1424e-05\n",
      "Epoch 120/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.5125e-05\n",
      "Epoch 00120: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 567ms/step - loss: 1.5125e-05 - val_loss: 1.0933e-05\n",
      "Epoch 121/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.4538e-05target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the increased information supplied by other agencies will be wasted.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present manual filing system is obsolete#>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "\n",
      "\n",
      "Epoch 00121: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 125s 611ms/step - loss: 1.4538e-05 - val_loss: 1.0453e-05\n",
      "Epoch 122/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.3952e-05\n",
      "Epoch 00122: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 116s 565ms/step - loss: 1.3952e-05 - val_loss: 9.9802e-06\n",
      "Epoch 123/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.3372e-05\n",
      "Epoch 00123: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 567ms/step - loss: 1.3372e-05 - val_loss: 9.5214e-06\n",
      "Epoch 124/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.2799e-05\n",
      "Epoch 00124: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 116s 565ms/step - loss: 1.2799e-05 - val_loss: 9.0697e-06\n",
      "Epoch 125/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.2233e-05\n",
      "Epoch 00125: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 569ms/step - loss: 1.2233e-05 - val_loss: 8.6340e-06\n",
      "Epoch 126/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.1679e-05target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the increased information supplied by other agencies will be wasted.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present manual filing system is obsolete#>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "\n",
      "\n",
      "Epoch 00126: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 128s 621ms/step - loss: 1.1679e-05 - val_loss: 8.2084e-06\n",
      "Epoch 127/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.1136e-05\n",
      "Epoch 00127: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 571ms/step - loss: 1.1136e-05 - val_loss: 7.8012e-06\n",
      "Epoch 128/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.0607e-05\n",
      "Epoch 00128: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 118s 572ms/step - loss: 1.0607e-05 - val_loss: 7.4071e-06\n",
      "Epoch 129/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.0090e-05\n",
      "Epoch 00129: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 118s 575ms/step - loss: 1.0090e-05 - val_loss: 7.0220e-06\n",
      "Epoch 130/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 9.5913e-06\n",
      "Epoch 00130: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 119s 577ms/step - loss: 9.5913e-06 - val_loss: 6.6624e-06\n",
      "Epoch 131/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 9.1065e-06target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the increased information supplied by other agencies will be wasted.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present manual filing system is obsolete#>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "\n",
      "\n",
      "Epoch 00131: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 126s 614ms/step - loss: 9.1065e-06 - val_loss: 6.3105e-06\n",
      "Epoch 132/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 8.6409e-06\n",
      "Epoch 00132: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 569ms/step - loss: 8.6409e-06 - val_loss: 5.9766e-06\n",
      "Epoch 133/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 8.1931e-06\n",
      "Epoch 00133: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 118s 574ms/step - loss: 8.1931e-06 - val_loss: 5.6584e-06\n",
      "Epoch 134/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 7.7637e-06\n",
      "Epoch 00134: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 118s 575ms/step - loss: 7.7637e-06 - val_loss: 5.3547e-06\n",
      "Epoch 135/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 7.3504e-06\n",
      "Epoch 00135: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 118s 575ms/step - loss: 7.3504e-06 - val_loss: 5.0681e-06\n",
      "Epoch 136/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 6.9601e-06target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the increased information supplied by other agencies will be wasted.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present manual filing system is obsolete#>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "\n",
      "\n",
      "Epoch 00136: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 126s 616ms/step - loss: 6.9601e-06 - val_loss: 4.7913e-06\n",
      "Epoch 137/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 6.5837e-06\n",
      "Epoch 00137: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 118s 574ms/step - loss: 6.5837e-06 - val_loss: 4.5322e-06\n",
      "Epoch 138/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 6.2320e-06\n",
      "Epoch 00138: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 118s 573ms/step - loss: 6.2320e-06 - val_loss: 4.2856e-06\n",
      "Epoch 139/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 5.8961e-06\n",
      "Epoch 00139: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 570ms/step - loss: 5.8961e-06 - val_loss: 4.0515e-06\n",
      "Epoch 140/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 5.5909e-06\n",
      "Epoch 00140: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 118s 572ms/step - loss: 5.5909e-06 - val_loss: 3.8395e-06\n",
      "Epoch 141/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 5.3486e-06target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the increased information supplied by other agencies will be wasted.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present manual filing system is obsolete#>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "\n",
      "\n",
      "Epoch 00141: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 125s 608ms/step - loss: 5.3486e-06 - val_loss: 3.6623e-06\n",
      "Epoch 142/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 6.8988e-06\n",
      "Epoch 00142: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 567ms/step - loss: 6.8988e-06 - val_loss: 3.8120e-06\n",
      "Epoch 143/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 9.8502e-06\n",
      "Epoch 00143: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 569ms/step - loss: 9.8502e-06 - val_loss: 3.9486e-06\n",
      "Epoch 144/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 2.1963e-05\n",
      "Epoch 00144: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 568ms/step - loss: 2.1963e-05 - val_loss: 4.6554e-06\n",
      "Epoch 145/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 2.2928e-05\n",
      "Epoch 00145: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 116s 563ms/step - loss: 2.2928e-05 - val_loss: 4.3546e-06\n",
      "Epoch 146/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 8.7283e-06target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the increased information supplied by other agencies will be wasted.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present manual filing system is obsolete#>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "\n",
      "\n",
      "Epoch 00146: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 125s 607ms/step - loss: 8.7283e-06 - val_loss: 3.9604e-06\n",
      "Epoch 147/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.6191e-05\n",
      "Epoch 00147: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 116s 564ms/step - loss: 1.6191e-05 - val_loss: 3.6310e-06\n",
      "Epoch 148/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 5.3319e-06\n",
      "Epoch 00148: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 569ms/step - loss: 5.3319e-06 - val_loss: 3.4741e-06\n",
      "Epoch 149/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 6.0353e-06\n",
      "Epoch 00149: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 116s 565ms/step - loss: 6.0353e-06 - val_loss: 3.2906e-06\n",
      "Epoch 150/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 7.0622e-06\n",
      "Epoch 00150: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 567ms/step - loss: 7.0622e-06 - val_loss: 3.1705e-06\n",
      "Epoch 151/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 4.0599e-06target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the increased information supplied by other agencies will be wasted.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present manual filing system is obsolete#>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "\n",
      "\n",
      "Epoch 00151: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 125s 610ms/step - loss: 4.0599e-06 - val_loss: 3.0341e-06\n",
      "Epoch 152/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 3.9107e-06\n",
      "Epoch 00152: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 570ms/step - loss: 3.9107e-06 - val_loss: 2.9173e-06\n",
      "Epoch 153/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 3.7792e-06\n",
      "Epoch 00153: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 116s 566ms/step - loss: 3.7792e-06 - val_loss: 2.8124e-06\n",
      "Epoch 154/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 3.6575e-06\n",
      "Epoch 00154: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 116s 564ms/step - loss: 3.6575e-06 - val_loss: 2.7154e-06\n",
      "Epoch 155/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 3.5422e-06\n",
      "Epoch 00155: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 570ms/step - loss: 3.5422e-06 - val_loss: 2.6226e-06\n",
      "Epoch 156/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 3.4315e-06target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the increased information supplied by other agencies will be wasted.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present manual filing system is obsolete#>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "\n",
      "\n",
      "Epoch 00156: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 125s 608ms/step - loss: 3.4315e-06 - val_loss: 2.5325e-06\n",
      "Epoch 157/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 3.3246e-06\n",
      "Epoch 00157: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 116s 564ms/step - loss: 3.3246e-06 - val_loss: 2.4471e-06\n",
      "Epoch 158/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 3.2207e-06\n",
      "Epoch 00158: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 567ms/step - loss: 3.2207e-06 - val_loss: 2.3637e-06\n",
      "Epoch 159/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 3.1195e-06\n",
      "Epoch 00159: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 116s 564ms/step - loss: 3.1195e-06 - val_loss: 2.2831e-06\n",
      "Epoch 160/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 3.0207e-06\n",
      "Epoch 00160: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 116s 565ms/step - loss: 3.0207e-06 - val_loss: 2.2054e-06\n",
      "Epoch 161/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 2.9241e-06target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the increased information supplied by other agencies will be wasted.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present manual filing system is obsolete#>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "\n",
      "\n",
      "Epoch 00161: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 125s 611ms/step - loss: 2.9241e-06 - val_loss: 2.1296e-06\n",
      "Epoch 162/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 2.8298e-06\n",
      "Epoch 00162: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 116s 565ms/step - loss: 2.8298e-06 - val_loss: 2.0564e-06\n",
      "Epoch 163/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 2.7377e-06\n",
      "Epoch 00163: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 116s 565ms/step - loss: 2.7377e-06 - val_loss: 1.9851e-06\n",
      "Epoch 164/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 2.6476e-06\n",
      "Epoch 00164: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 566ms/step - loss: 2.6476e-06 - val_loss: 1.9160e-06\n",
      "Epoch 165/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 2.5598e-06\n",
      "Epoch 00165: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 116s 566ms/step - loss: 2.5598e-06 - val_loss: 1.8493e-06\n",
      "Epoch 166/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 2.4741e-06target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the increased information supplied by other agencies will be wasted.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present manual filing system is obsolete#>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "\n",
      "\n",
      "Epoch 00166: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 125s 610ms/step - loss: 2.4741e-06 - val_loss: 1.7841e-06\n",
      "Epoch 167/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 2.3906e-06\n",
      "Epoch 00167: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 116s 565ms/step - loss: 2.3906e-06 - val_loss: 1.7212e-06\n",
      "Epoch 168/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 2.3093e-06\n",
      "Epoch 00168: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 569ms/step - loss: 2.3093e-06 - val_loss: 1.6599e-06\n",
      "Epoch 169/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 2.2304e-06\n",
      "Epoch 00169: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 570ms/step - loss: 2.2304e-06 - val_loss: 1.6010e-06\n",
      "Epoch 170/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 2.1537e-06\n",
      "Epoch 00170: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 568ms/step - loss: 2.1537e-06 - val_loss: 1.5444e-06\n",
      "Epoch 171/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 2.0793e-06target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the increased information supplied by other agencies will be wasted.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present manual filing system is obsolete#>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "\n",
      "\n",
      "Epoch 00171: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 127s 617ms/step - loss: 2.0793e-06 - val_loss: 1.4891e-06\n",
      "Epoch 172/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 2.0073e-06\n",
      "Epoch 00172: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 568ms/step - loss: 2.0073e-06 - val_loss: 1.4361e-06\n",
      "Epoch 173/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.9376e-06\n",
      "Epoch 00173: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 118s 575ms/step - loss: 1.9376e-06 - val_loss: 1.3857e-06\n",
      "Epoch 174/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.8702e-06\n",
      "Epoch 00174: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 118s 575ms/step - loss: 1.8702e-06 - val_loss: 1.3366e-06\n",
      "Epoch 175/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.8052e-06\n",
      "Epoch 00175: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 571ms/step - loss: 1.8052e-06 - val_loss: 1.2897e-06\n",
      "Epoch 176/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.7425e-06target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the increased information supplied by other agencies will be wasted.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present manual filing system is obsolete#>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "\n",
      "\n",
      "Epoch 00176: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 127s 616ms/step - loss: 1.7425e-06 - val_loss: 1.2443e-06\n",
      "Epoch 177/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.6821e-06\n",
      "Epoch 00177: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 569ms/step - loss: 1.6821e-06 - val_loss: 1.2010e-06\n",
      "Epoch 178/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.6240e-06\n",
      "Epoch 00178: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 118s 575ms/step - loss: 1.6240e-06 - val_loss: 1.1594e-06\n",
      "Epoch 179/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.5682e-06\n",
      "Epoch 00179: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 118s 575ms/step - loss: 1.5682e-06 - val_loss: 1.1194e-06\n",
      "Epoch 180/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.5145e-06\n",
      "Epoch 00180: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 119s 578ms/step - loss: 1.5145e-06 - val_loss: 1.0815e-06\n",
      "Epoch 181/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.4630e-06target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the increased information supplied by other agencies will be wasted.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present manual filing system is obsolete#>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "\n",
      "\n",
      "Epoch 00181: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 128s 622ms/step - loss: 1.4630e-06 - val_loss: 1.0448e-06\n",
      "Epoch 182/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.4135e-06\n",
      "Epoch 00182: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 118s 571ms/step - loss: 1.4135e-06 - val_loss: 1.0101e-06\n",
      "Epoch 183/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.3661e-06\n",
      "Epoch 00183: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 118s 574ms/step - loss: 1.3661e-06 - val_loss: 9.7628e-07\n",
      "Epoch 184/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.3206e-06\n",
      "Epoch 00184: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 119s 577ms/step - loss: 1.3206e-06 - val_loss: 9.4439e-07\n",
      "Epoch 185/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.2772e-06\n",
      "Epoch 00185: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 118s 572ms/step - loss: 1.2772e-06 - val_loss: 9.1366e-07\n",
      "Epoch 186/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.2355e-06target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the increased information supplied by other agencies will be wasted.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present manual filing system is obsolete#>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "\n",
      "\n",
      "Epoch 00186: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 127s 616ms/step - loss: 1.2355e-06 - val_loss: 8.8453e-07\n",
      "Epoch 187/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.1957e-06\n",
      "Epoch 00187: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 568ms/step - loss: 1.1957e-06 - val_loss: 8.5658e-07\n",
      "Epoch 188/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.1575e-06\n",
      "Epoch 00188: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 116s 566ms/step - loss: 1.1575e-06 - val_loss: 8.2991e-07\n",
      "Epoch 189/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.1210e-06\n",
      "Epoch 00189: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 568ms/step - loss: 1.1210e-06 - val_loss: 8.0435e-07\n",
      "Epoch 190/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.0862e-06\n",
      "Epoch 00190: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 119s 578ms/step - loss: 1.0862e-06 - val_loss: 7.7998e-07\n",
      "Epoch 191/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.0528e-06target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the increased information supplied by other agencies will be wasted.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present manual filing system is obsolete#>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "\n",
      "\n",
      "Epoch 00191: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 126s 613ms/step - loss: 1.0528e-06 - val_loss: 7.5654e-07\n",
      "Epoch 192/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 1.0209e-06\n",
      "Epoch 00192: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 118s 572ms/step - loss: 1.0209e-06 - val_loss: 7.3422e-07\n",
      "Epoch 193/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 9.9054e-07\n",
      "Epoch 00193: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 118s 576ms/step - loss: 9.9054e-07 - val_loss: 7.1271e-07\n",
      "Epoch 194/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 9.6145e-07\n",
      "Epoch 00194: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 118s 572ms/step - loss: 9.6145e-07 - val_loss: 6.9216e-07\n",
      "Epoch 195/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 9.3355e-07\n",
      "Epoch 00195: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 570ms/step - loss: 9.3355e-07 - val_loss: 6.7264e-07\n",
      "Epoch 196/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 9.0697e-07target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: <the increased information supplied by other agencies will be wasted.>\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: <its present manual filing system is obsolete#>\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "\n",
      "\n",
      "Epoch 00196: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 127s 618ms/step - loss: 9.0697e-07 - val_loss: 6.5405e-07\n",
      "Epoch 197/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 8.8147e-07\n",
      "Epoch 00197: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 569ms/step - loss: 8.8147e-07 - val_loss: 6.3623e-07\n",
      "Epoch 198/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 8.5718e-07\n",
      "Epoch 00198: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 117s 569ms/step - loss: 8.5718e-07 - val_loss: 6.1915e-07\n",
      "Epoch 199/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 8.3380e-07\n",
      "Epoch 00199: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 118s 572ms/step - loss: 8.3380e-07 - val_loss: 6.0256e-07\n",
      "Epoch 200/200\n",
      "205/205 [==============================] - ETA: 0s - loss: 8.1155e-07\n",
      "Epoch 00200: saving model to training_checkpoint\\cp.ckpt\n",
      "205/205 [==============================] - 118s 572ms/step - loss: 8.1155e-07 - val_loss: 5.8683e-07\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(val_ds))\n",
    "\n",
    "# The vocabulary to convert predicted indices into characters\n",
    "idx_to_char = vectorizer.get_vocabulary()\n",
    "display_cb = DisplayOutputs(\n",
    "    batch, idx_to_char, target_start_token_idx=2, target_end_token_idx=3\n",
    ")  # set the arguments as per vocabulary index for '<' and '>'\n",
    "\n",
    "model = Transformer(\n",
    "    num_hid=200,\n",
    "    num_head=2,\n",
    "    num_feed_forward=400,\n",
    "    target_maxlen=max_target_len,\n",
    "    num_layers_enc=5,\n",
    "    num_layers_dec=3,\n",
    "    num_classes=vocab_size, #original = num_classes=34,\n",
    ")\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "    label_smoothing=0.1,\n",
    ")\n",
    "\n",
    "learning_rate = CustomSchedule(\n",
    "    init_lr=0.00001,\n",
    "    lr_after_warmup=0.001,\n",
    "    final_lr=0.00001,\n",
    "    warmup_epochs=15,\n",
    "    decay_epochs=85,\n",
    "    steps_per_epoch=len(ds),\n",
    ")\n",
    "\n",
    "#carregar o modelo pre-treinado\n",
    "#model.load_weights('pre_lj_pesos.h5')\n",
    "#model.load_weights('pre_ua_pesos.h5')\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "model.compile(optimizer=optimizer, loss=loss_fn)\n",
    "\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=5)\n",
    "\n",
    "'''\n",
    "# Congela as últimas camadas do codificador\n",
    "num_camadas_para_congelar = 2  # Altere o número de camadas que deseja congelar\n",
    "for camada in model.encoder.layers[-num_camadas_para_congelar:]:\n",
    "    camada.trainable = False\n",
    "\n",
    "# Verifica quais camadas estão congeladas\n",
    "for camada in model.encoder.layers:\n",
    "    print(camada.name, camada.trainable)\n",
    "'''\n",
    "\n",
    "checkpoint_path = \"training_checkpoint/cp.ckpt\"\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)\n",
    "checkpoint_manager = tf.train.CheckpointManager(checkpoint, checkpoint_path, max_to_keep=3)\n",
    "status = checkpoint.restore(checkpoint_manager.latest_checkpoint)\n",
    "\n",
    "  # train\n",
    "\n",
    "#load_checkpoint(checkpoint, checkpoint_manager)\n",
    "\n",
    "model_ccheckpoint_path = 'tmp/chechpoint/cp.ckpt'\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=model_ccheckpoint_path,\n",
    "                                                         save_weights_only=True,\n",
    "                                                         verbose=1)\n",
    "while True:\n",
    "    history = model.fit(ds, validation_data=val_ds, callbacks=[display_cb, checkpoint_callback, tensorboard_callback], epochs=200)\n",
    "    manager.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AWXGWnClRHCi"
   },
   "source": [
    "In practice, you should train for around 100 epochs or more.\n",
    "\n",
    "Some of the predicted text at or around epoch 35 may look as follows:\n",
    "```\n",
    "target:     <as they sat in the car, frazier asked oswald where his lunch was>\n",
    "prediction: <as they sat in the car frazier his lunch ware mis lunch was>\n",
    "\n",
    "target:     <under the entry for may one, nineteen sixty,>\n",
    "prediction: <under the introus for may monee, nin the sixty,>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva o modelo final\n",
    "model.save_weights('pre_lj_pesos.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " speech_feature_embedding (S  (None, None, 200)        1164400   \n",
      " peechFeatureEmbedding)                                          \n",
      "                                                                 \n",
      " token_embedding (TokenEmbed  multiple                 46800     \n",
      " ding)                                                           \n",
      "                                                                 \n",
      " sequential_5 (Sequential)   (None, None, 200)         3587400   \n",
      "                                                                 \n",
      " transformer_decoder (Transf  multiple                 804600    \n",
      " ormerDecoder)                                                   \n",
      "                                                                 \n",
      " transformer_decoder_1 (Tran  multiple                 804600    \n",
      " sformerDecoder)                                                 \n",
      "                                                                 \n",
      " transformer_decoder_2 (Tran  multiple                 804600    \n",
      " sformerDecoder)                                                 \n",
      "                                                                 \n",
      " dense_6 (Dense)             multiple                  6834      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,054,836\n",
      "Trainable params: 6,054,834\n",
      "Non-trainable params: 2\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotina de testes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Somente computa o WRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Progbar\n",
    "import tensorflow as tf\n",
    "\n",
    "class CalculateWRA(keras.callbacks.Callback):\n",
    "    def __init__(\n",
    "        self, val_ds, idx_to_token, target_start_token_idx=27, target_end_token_idx=28\n",
    "    ):\n",
    "        \"\"\"Calculates Word Recognition Accuracy (WRA) after every epoch\n",
    "\n",
    "        Args:\n",
    "            val_ds: Validation dataset containing the keys \"source\" and \"target\"\n",
    "            idx_to_token: A List containing the vocabulary tokens corresponding to their indices\n",
    "            target_start_token_idx: A start token index in the target vocabulary\n",
    "            target_end_token_idx: An end token index in the target vocabulary\n",
    "        \"\"\"\n",
    "        self.val_ds = val_ds\n",
    "        self.target_start_token_idx = target_start_token_idx\n",
    "        self.target_end_token_idx = target_end_token_idx\n",
    "        self.idx_to_char = idx_to_token\n",
    "\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        total_count = 0\n",
    "        correct_count = 0\n",
    "        precision_list = []\n",
    "        num_batches = tf.data.experimental.cardinality(self.val_ds).numpy()\n",
    "        progbar = Progbar(target=num_batches, stateful_metrics=['correct_count', 'total_count'])\n",
    "\n",
    "        for batch_num, batch in enumerate(self.val_ds):\n",
    "            source = batch[\"source\"]\n",
    "            target = batch[\"target\"].numpy()\n",
    "            bs = tf.shape(source)[0]\n",
    "            preds = model.generate(source, self.target_start_token_idx)\n",
    "            preds = preds.numpy()\n",
    "    \n",
    "            for i in range(bs):\n",
    "                target_text = \"\".join([self.idx_to_char[_] for _ in target[i, :]])\n",
    "                prediction = \"\"\n",
    "                for idx in preds[i, :]:\n",
    "                    prediction += self.idx_to_char[idx]\n",
    "                    if idx == self.target_end_token_idx:\n",
    "                        break\n",
    "\n",
    "                #total_count += 1\n",
    "                #if target_text.strip() == prediction.strip():\n",
    "                #    correct_count += 1\n",
    "            def calculate_precision(target_text, prediction):\n",
    "                \n",
    "                target_words = set(target_text.split())\n",
    "                prediction_words = set(prediction.split())\n",
    "            \n",
    "                common_words = target_words.intersection(prediction_words)\n",
    "            \n",
    "                precision = len(common_words) / len(target_words)\n",
    "                precision_list.append(precision) \n",
    "                return precision, common_words, target_words, precision_list       \n",
    "\n",
    "            precision, common_words, target_words, precision_list = calculate_precision(target_text, prediction)\n",
    "            #print(precision_list)\n",
    "            progbar.update(batch_num+1, values=[('wra', precision),('correct_count', len(common_words)), ('total_count', len(target_words))])\n",
    "            \n",
    "        print(f\"A precisão é de {np.mean(precision_list) * 100}%\\n\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6/33 [====>.........................] - ETA: 4:14 - wra: 0.2871 - correct_count: 3.0000 - total_count: 15.0000    "
     ]
    }
   ],
   "source": [
    "calculate_wra = CalculateWRA(val_ds=val_ds, idx_to_token=idx_to_char, target_start_token_idx=27)\n",
    "calculate_wra.on_epoch_end(epoch=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calcula WRA e mostra palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('pre_lj_pesos.h5')\n",
    "\n",
    "class EvaluateModel(keras.callbacks.Callback):\n",
    "    def __init__(self, val_ds, idx_to_token, target_start_token_idx=27, target_end_token_idx=28):\n",
    "        self.val_ds = val_ds\n",
    "        self.target_start_token_idx = target_start_token_idx\n",
    "        self.target_end_token_idx = target_end_token_idx\n",
    "        self.idx_to_char = idx_to_token\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        total_count = 0\n",
    "        correct_count = 0\n",
    "        for i, batch in enumerate(self.val_ds):\n",
    "            source = batch[\"source\"]\n",
    "            target = batch[\"target\"].numpy()\n",
    "            bs = tf.shape(source)[0]\n",
    "            preds = model.generate(source, self.target_start_token_idx)\n",
    "            preds = preds.numpy()\n",
    "            for i in range(bs):\n",
    "                target_text = \"\".join([self.idx_to_char[_] for _ in target[i, :]])\n",
    "                prediction = \"\"\n",
    "                for idx in preds[i, :]:\n",
    "                    prediction += self.idx_to_char[idx]\n",
    "                    if idx == self.target_end_token_idx:\n",
    "                        break\n",
    "                print(f\"target:     {target_text.replace('-','')}\")\n",
    "                print(f\"prediction: {prediction}\\n\")\n",
    "\n",
    "            def calculate_precision(target_text, prediction):\n",
    "                # Dividir as strings em palavras\n",
    "                target_words = set(target_text.split())\n",
    "                prediction_words = set(prediction.split())\n",
    "            \n",
    "                # Encontrar a interseção das palavras\n",
    "                common_words = target_words.intersection(prediction_words)\n",
    "            \n",
    "                # Calcular a precisão\n",
    "                precision = len(common_words) / len(target_words)\n",
    "            \n",
    "                return precision\n",
    "        \n",
    "\n",
    "            precision = calculate_precision(target_text, prediction)\n",
    "\n",
    "            print(f\"A precisão é de {precision * 100}%\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target:     <the increased information supplied by other agencies will be wasted.>\n",
      "prediction: x>libe wasted.>information supplied by\n",
      "\n",
      "target:     <prs must develop the capacity to classify its subjects on a more sophisticated basis than the present geographic breakdown.>\n",
      "prediction: xt, vellop the capacity\n",
      "\n",
      "target:     <its present manual filing system is obsolete#>\n",
      "prediction: xoley\n",
      "\n",
      "target:     <it makes no use of the recent developments in automatic data processing which are widely used in the business world and in other government offices.>\n",
      "prediction: x.>with awes din the business world and in other government offices. which ar widly\n",
      "\n",
      "A precisão é de 36.36363636363637%\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21968\\2562790665.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcallback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEvaluateModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx_to_token\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midx_to_char\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21968\\4106649324.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, logs)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0msource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"source\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"target\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mbs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_start_token_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m                 \u001b[0mtarget_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midx_to_char\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21968\\2210952819.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, source, target_start_token_idx)\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[0menc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[0mdec_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtarget_start_token_idx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[0mdec_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_maxlen\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0mdec_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdec_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdec_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m             \u001b[0mlast_logit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21968\\2210952819.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, enc_out, target)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menc_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdec_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_layers_dec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf\"dec_layer_{i}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\asr_keras\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\envs\\asr_keras\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1088\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0meager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1089\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_saved_model_inputs_spec\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_save_spec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1092\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\envs\\asr_keras\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[0mnew_e\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mnew_e\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m       \u001b[1;32mdel\u001b[0m \u001b[0mbound_signature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21968\\3855558651.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, enc_out, target)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mtarget_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayernorm1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mself_dropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_att\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0menc_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menc_att\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menc_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0menc_out_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayernorm2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menc_dropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc_out\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtarget_norm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mffn_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mffn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc_out_norm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mffn_out_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayernorm3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc_out_norm\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mffn_dropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mffn_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mffn_out_norm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\asr_keras\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\envs\\asr_keras\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1088\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0meager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1089\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_saved_model_inputs_spec\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_save_spec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1092\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\envs\\asr_keras\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[0mnew_e\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mnew_e\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m       \u001b[1;32mdel\u001b[0m \u001b[0mbound_signature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\envs\\asr_keras\\lib\\site-packages\\keras\\layers\\core\\dropout.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m    107\u001b[0m           \u001b[0mnoise_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_noise_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m           \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m           rate=self.rate)\n\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m     output = control_flow_util.smart_cond(training, dropped_inputs,\n\u001b[0m\u001b[0;32m    112\u001b[0m                                           lambda: tf.identity(inputs))\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\asr_keras\\lib\\site-packages\\keras\\utils\\control_flow_util.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[0;32m    101\u001b[0m   \"\"\"\n\u001b[0;32m    102\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m     return tf.cond(\n\u001b[0;32m    104\u001b[0m         pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[1;32m--> 105\u001b[1;33m   return tf.__internal__.smart_cond.smart_cond(\n\u001b[0m\u001b[0;32m    106\u001b[0m       pred, true_fn=true_fn, false_fn=false_fn, name=name)\n",
      "\u001b[1;32m~\\miniconda3\\envs\\asr_keras\\lib\\site-packages\\tensorflow\\python\\framework\\smart_cond.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[0;32m     55\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mpred_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpred_value\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     return control_flow_ops.cond(pred, true_fn=true_fn, false_fn=false_fn,\n\u001b[0;32m     62\u001b[0m                                  name=name)\n",
      "\u001b[1;32m~\\miniconda3\\envs\\asr_keras\\lib\\site-packages\\keras\\layers\\core\\dropout.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m                                           lambda: tf.identity(inputs))\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\envs\\asr_keras\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\envs\\asr_keras\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mOpDispatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1103\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1104\u001b[1;33m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\envs\\asr_keras\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(input, name)\u001b[0m\n\u001b[0;32m    286\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"graph\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m     \u001b[1;31m# Make sure we get an input with handle data attached from resource\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[1;31m# variables. Variables have correct handle data when graph building.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m     \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 290\u001b[1;33m   \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    291\u001b[0m   \u001b[1;31m# Propagate handle data for happier shape inference for resource variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_handle_data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_data\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\asr_keras\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(input, name)\u001b[0m\n\u001b[0;32m   4065\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4066\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4067\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4068\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4069\u001b[1;33m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4070\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4071\u001b[0m       return identity_eager_fallback(\n\u001b[0;32m   4072\u001b[0m           input, name=name, ctx=_ctx)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "callback = EvaluateModel(val_ds=val_ds, idx_to_token=idx_to_char)\n",
    "callback.model = model \n",
    "callback.on_train_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "transformer_asr",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
